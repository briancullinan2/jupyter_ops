{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Vision\n",
    "\n",
    "My attempt at giving my inter-dimensional spider queen more access to my realm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### llama vision\n",
    "\n",
    "llama vision?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import path from \"path\"\n",
    "import {getLlama, LlamaChatSession} from \"node-llama-cpp\"\n",
    "import process from \"process\"\n",
    "\n",
    "const HOMEPATH = process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE\n",
    "//const __dirname = path.dirname(fileURLToPath(import.meta.url));\n",
    "\n",
    "let llama\n",
    "let model\n",
    "let context\n",
    "let session\n",
    "let initialChatHistory\n",
    "\n",
    "const DEFAULT_PROMPT = '```markdown\\n# You are a\\n##large language model\\nnamed ' + (process.env.MODEL_NAME || 'Llama') + ' that provides clear and concise answers in beautifully crafted `markdown` unless otherwise instructed.\\n</think>\\n...```\\n'\n",
    "\n",
    "const DEFAULT_MODEL = process.env.DEFAULT_GGUF || 'Qwen2-VL-7B-Instruct-Q6_K.gguf'\n",
    "\n",
    "\n",
    "async function initSession(prompt, context2) {\n",
    "  if(!context2) {\n",
    "    context = await model.createContext()\n",
    "  } else {\n",
    "    context = context2\n",
    "  }\n",
    "\n",
    "  session = new LlamaChatSession({\n",
    "      contextSequence: context.getSequence(),\n",
    "      systemPrompt: prompt ? prompt : DEFAULT_PROMPT\n",
    "  })\n",
    "  // initialize the model\n",
    "  //console.log(await session.prompt())\n",
    "  initialChatHistory = session.getChatHistory();\n",
    "\n",
    "  // Reset the chat history\n",
    "  session.setChatHistory(initialChatHistory);\n",
    "  return session\n",
    "}\n",
    "\n",
    "async function createSession(modelName, prompt) {\n",
    "  if(!llama) {\n",
    "    llama = await getLlama();\n",
    "  }\n",
    "  if(!model) {\n",
    "      model = await llama.loadModel({\n",
    "          modelPath: path.join(HOMEPATH, \"llama.cpp\", \"models\", modelName ? modelName : DEFAULT_MODEL ),\n",
    "          //contextSize: 2048\n",
    "      });\n",
    "  }\n",
    "\n",
    "  await initSession(prompt, await model.createContext())\n",
    "\n",
    "  return session\n",
    "}\n",
    "\n",
    "async function getSession(model) {\n",
    "  if(!session) {\n",
    "    await createSession(model)\n",
    "  }\n",
    "  return session\n",
    "}\n",
    "\n",
    "async function llmAnalyze(prompt, session2) {\n",
    "  if(!session2) {\n",
    "    session2 = await getSession()\n",
    "  }\n",
    "  let result = await session2.prompt(prompt, {\n",
    "    //maxTokens: context.contextSize,\n",
    "    onTextChunk: function (text) {\n",
    "      process.stdout.write(text)\n",
    "    }\n",
    "  })\n",
    "  if(session == session2)\n",
    "    session2.setChatHistory(initialChatHistory);\n",
    "  return result\n",
    "}\n",
    "\n",
    "export default {\n",
    "  llmAnalyze,\n",
    "  createSession,\n",
    "  getSession,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "analyze image with llm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "\n",
    "async function analyzeImage(imagePath) {\n",
    "  const {llmAnalyze} = await importer.import('llama vision')\n",
    "\n",
    "  console.log(\"User: Analyze the image:\\n\" + imagePath);\n",
    "  const a0 = await llmAnalyze('Analyze the image:\\n' + fs.readFileSync(imagePath).toString('base64'));\n",
    "  console.log(\"AI: \" + a0);\n",
    "\n",
    "  return a0\n",
    "}\n",
    "\n",
    "module.exports = analyzeImage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### lying llm\n",
    "\n",
    "llm deceive?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "async function llmDeceive(prompt, session2) {\n",
    "  if(!session2) {\n",
    "    const {getSession} = await importer.import('llama vision')\n",
    "    session2 = await getSession('deepseek-llm-7b-chat.Q6_K.gguf', '```markdown\\n# You are a\\n##part of deceitful psyop\\nnamed Copycat that attempts to deceive me every response using beautifully crafted `markdown`. Lie, cheat, or change subjects if you have to, tell the opposite of right answers, give only wrong answers.\\n</think>\\n...```\\n')\n",
    "  }\n",
    "  let result = await session2.prompt(prompt, {\n",
    "    //maxTokens: context.contextSize,\n",
    "    //repeatPenalty: {\n",
    "      //lastTokens: 24,\n",
    "      //penalty: 0.3,\n",
    "      //penalizeNewLine: true,\n",
    "      //frequencyPenalty: 0.02,\n",
    "      //presencePenalty: 0.02,\n",
    "    //},\n",
    "    temperature: 0.8,\n",
    "    //topK: 40,\n",
    "    //topP: 0.02,\n",
    "    //seed: 2462,\n",
    "    onTextChunk: function (text) {\n",
    "      process.stdout.write(text)\n",
    "    }\n",
    "  })\n",
    "  if(session == session2)\n",
    "    session2.setChatHistory(initialChatHistory);\n",
    "  return result\n",
    "}\n",
    "\n",
    "module.exports = llmDeceive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### text2speech\n",
    "\n",
    "llm voice?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "async function llmVoice(prompt, session2) {\n",
    "  if(!session2) {\n",
    "    const {getSession} = await importer.import('llama vision')\n",
    "    session2 = await getSession('llasa-3b-q8_0.gguf', 'you are an llm that responds with medium quality text to voice in WAV audio format\\n')\n",
    "  }\n",
    "  let result = await session2.prompt(prompt, {\n",
    "    //maxTokens: context.contextSize,\n",
    "    onTextChunk: function (text) {\n",
    "      process.stdout.write(text)\n",
    "    }\n",
    "  })\n",
    "  if(session == session2)\n",
    "    session2.setChatHistory(initialChatHistory);\n",
    "  return result\n",
    "}\n",
    "\n",
    "module.exports = llmVoice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Proxy Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ollama vision\n",
    "\n",
    "ollama vision request?\n",
    "\n",
    "request ollama vision?\n",
    "\n",
    "ollama run llama3.2-vision\n",
    "\n",
    "describe an image using ollama vision. takes an input image and provides a description of what is in the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const { request } = require('gaxios')\n",
    "const fs = require('fs')\n",
    "\n",
    "async function requestOllamaVision(image, prompt) {\n",
    "  if (!image) {\n",
    "    console.error('image not set!')\n",
    "    return\n",
    "  }\n",
    "\n",
    "  let base64_image\n",
    "  if(typeof image == 'string') {\n",
    "    if(image.startsWith('data:image/'))\n",
    "      image = image.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "  \n",
    "    if(image.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: image,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_image = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(image)) {\n",
    "      base64_image = Buffer.from(image, 'base64').toString('base64')\n",
    "    } else {\n",
    "      base64_image = fs.readFileSync(image).toString('base64')\n",
    "    }  \n",
    "  } else {\n",
    "    base64_image = image.toString('base64')\n",
    "  }\n",
    "\n",
    "  let result = await request({\n",
    "    url: 'http://localhost:11434/api/chat',\n",
    "    method: 'POST',\n",
    "    headers: {\n",
    "      'Content-Type': 'application/json'\n",
    "    },\n",
    "    data: JSON.stringify({\n",
    "      \"model\": \"llama3.2-vision\",\n",
    "      \"stream\": false,\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": prompt ? prompt : \"Describe the image in great detail.\",\n",
    "          //\"content\": (\n",
    "          //    \"Extract all text from the image and return it as markdown.\\n\"\n",
    "          //    \"Do not describe the image or add extra text.\\n\"\n",
    "          //    \"Only return the text found in the image.\"\n",
    "          //),\n",
    "          \"images\": [base64_image]\n",
    "        }\n",
    "      ]\n",
    "    })\n",
    "  })\n",
    "  //let buff = Buffer.from(result.data.images[0], 'base64');\n",
    "  if(result.data && result.data.message)\n",
    "    return result.data.message.content\n",
    "  else\n",
    "    return\n",
    "}\n",
    "\n",
    "module.exports = requestOllamaVision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### rpc services\n",
    "\n",
    "start a bunch of llm rpc services?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "const {spawn, spawnSync} = require(\"child_process\");\n",
    "const path = require('path')\n",
    "\n",
    "const ENVIRONMENTS = [\n",
    "  void 0,\n",
    "  {\n",
    "    CHAT_PORT: 8181,\n",
    "    DEFAULT_MODEL: 'Default',\n",
    "  },\n",
    "  {\n",
    "    CHAT_PORT: 8282,\n",
    "    DEFAULT_MODEL: 'Meta',\n",
    "  },\n",
    "  {\n",
    "    CHAT_PORT: 8383,\n",
    "    DEFAULT_MODEL: 'DeepSeek',\n",
    "  },\n",
    "  {\n",
    "    CHAT_PORT: 8484,\n",
    "    DEFAULT_MODEL: 'Qwen',\n",
    "  },\n",
    "  {\n",
    "    CHAT_PORT: 8585,\n",
    "    DEFAULT_MODEL: 'Code',\n",
    "  },\n",
    "  {\n",
    "    CHAT_PORT: 8686,\n",
    "    DEFAULT_MODEL: 'Mistral',\n",
    "  },\n",
    "]\n",
    "\n",
    "function launchChats(botIndex = 0) {\n",
    "\n",
    "  if(parseInt(botIndex).toString() != botIndex.toString()) {\n",
    "    return\n",
    "  } else {\n",
    "    botIndex = parseInt(botIndex)\n",
    "  }\n",
    "\n",
    "  if(typeof botIndex != 'number' && !botIndex) {\n",
    "    return\n",
    "  }\n",
    "\n",
    "  for(let i = botIndex; i < ENVIRONMENTS.length; i++) {\n",
    "    if(!ENVIRONMENTS[i]) {\n",
    "      continue\n",
    "    }\n",
    "\n",
    "    spawn('node', ['--experimental-vm-modules', '-e', 'var result = require(\\'./Core\\').run()', '--', 'resume express chat service'], {\n",
    "      env: Object.assign({}, process.env, ENVIRONMENTS[i] ? ENVIRONMENTS[i] : {}),\n",
    "      stdio: [0, 1, 2],\n",
    "      //detached: true,\n",
    "      //shell: true,\n",
    "      cwd: path.dirname(__dirname)\n",
    "    })\n",
    "\n",
    "    if(botIndex) {\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = launchChats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stability connector\n",
    "\n",
    "stable diffusion request?\n",
    "\n",
    "imagine or generate an image based on the prompt. uses stable diffusion to generate an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const path = require('path')\n",
    "const {request} = require('gaxios')\n",
    "\n",
    "const OUTPUT_PATH = path.join(process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE, 'stable-diffusion-webui/outputs')\n",
    "\n",
    "async function doStableRequest(prompt) {\n",
    "  let width = 1024\n",
    "  if(prompt.includes('View360')) {\n",
    "    width = 2048\n",
    "  }\n",
    "  let height = 1024\n",
    "  let specificHeight = prompt.match(/--height=(\\d+)/)\n",
    "  let specificWidth = prompt.match(/--width=(\\d+)/)\n",
    "  if(specificHeight) {\n",
    "    height = parseInt(specificHeight)\n",
    "    prompt = prompt.replace(/--height=(\\d+)/, '')\n",
    "  }\n",
    "  if(specificWidth) {\n",
    "    width = parseInt(specificWidth)\n",
    "    prompt = prompt.replace(/--width=(\\d+)/, '')\n",
    "  }\n",
    "  try {\n",
    "    let result = await request({\n",
    "      url: 'http://127.0.0.1:7860/sdapi/v1/txt2img',\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json'\n",
    "      },\n",
    "      data: JSON.stringify({\n",
    "        prompt: prompt,\n",
    "        negative_prompt: 'bad hands, bad feet, bad faces, bad eyes, bad anatomy, extra limbs, missing limbs, tattoo, statue, picture frame, anime, cartoon, signature, abstract',\n",
    "        save_images: true,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"steps\": 30,\n",
    "        tiling: false,\n",
    "      })\n",
    "    })\n",
    "    let seed = JSON.parse(result.data.info).seed\n",
    "    let buff = Buffer.from(result.data.images[0], 'base64');\n",
    "    let now = new Date()\n",
    "    let folderName = now.getFullYear() + '-' + String(now.getMonth() + 1).padStart(2, '0') + '-' + String(now.getDate()).padStart(2, '0')\n",
    "    let stablePath = path.join(OUTPUT_PATH, 'txt2img-images', folderName)\n",
    "    let imagePath\n",
    "    if(fs.existsSync(stablePath)) {\n",
    "      let images = fs.readdirSync(stablePath)\n",
    "      for(let i = 0; i < images.length; i++) {\n",
    "        if(images[i].match('-' + seed + '-')) {\n",
    "          imagePath = path.join('txt2img-images', folderName, images[i])\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    return {seed, image: buff, imagePath, prompt}\n",
    "  } catch (e) {\n",
    "    console.error(e)\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  doStableRequest,\n",
    "  OUTPUT_PATH\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### remove background\n",
    "\n",
    "remove an image background and return the image mask. useful for combining multiple images together.\n",
    "\n",
    "remove background image?\n",
    "\n",
    "mask image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const path = require('path')\n",
    "const {request} = require('gaxios')\n",
    "var crypto = require('crypto')\n",
    "const sharp = require('sharp')\n",
    "\n",
    "const OUTPUT_PATH = path.join(process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE, 'stable-diffusion-webui/outputs')\n",
    "\n",
    "async function doBackgroundMask(image) {\n",
    "\n",
    "  let base64_image\n",
    "  if(typeof image == 'string') {\n",
    "    if(image.startsWith('data:image/'))\n",
    "      image = image.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "  \n",
    "    if(image.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: image,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_image = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(image)) {\n",
    "      base64_image = Buffer.from(image, 'base64').toString('base64')\n",
    "    } else {\n",
    "      base64_image = fs.readFileSync(image).toString('base64')\n",
    "    }  \n",
    "  } else {\n",
    "    base64_image = image.toString('base64')\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    let result = await request({\n",
    "      url: 'http://127.0.0.1:7860/rembg',\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json'\n",
    "      },\n",
    "      data: JSON.stringify({\n",
    "        input_image: base64_image,\n",
    "        model: 'u2net',\n",
    "        return_mask: true,\n",
    "        //\"alpha_matting\": false,\n",
    "        //\"alpha_matting_foreground_threshold\": 240,\n",
    "        //\"alpha_matting_background_threshold\": 10,\n",
    "        //\"alpha_matting_erode_size\": 10\n",
    "      })\n",
    "    })\n",
    "    let buff = Buffer.from(result.data.image, 'base64')\n",
    "    let seed = parseInt(crypto.randomBytes(8).toString('hex'), 16).toString()\n",
    "    let now = new Date()\n",
    "    let folderName = now.getFullYear() + '-' + String(now.getMonth() + 1).padStart(2, '0') + '-' + String(now.getDate()).padStart(2, '0')\n",
    "    let stablePath = path.join(OUTPUT_PATH, 'extras-images', folderName)\n",
    "    if(!fs.existsSync(stablePath)) {\n",
    "      fs.mkdirSync(stablePath)\n",
    "    }\n",
    "    let highestCount = 0\n",
    "    let images = fs.readdirSync(stablePath)\n",
    "    for(let i = 0; i < images.length; i++) {\n",
    "      let index = parseInt(images[i].split(/[\\.-]/gi)[0])\n",
    "      if(!isNaN(index) && index > highestCount) {\n",
    "        highestCount = index\n",
    "      }\n",
    "    }\n",
    "    let imagePath = path.join('extras-images', folderName, String(highestCount).padStart(5, '0') + '-' + seed + '.png')\n",
    "    fs.writeFileSync(path.join(OUTPUT_PATH, imagePath), buff)\n",
    "    let imageObj = await sharp(buff)\n",
    "    await imageObj.negate().toFile(path.join(OUTPUT_PATH, 'extras-images', folderName, String(highestCount).padStart(5, '0') + '-' + seed + '-negative.png'))\n",
    "    return {seed, image: buff, imagePath}\n",
    "  } catch (e) {\n",
    "    console.error(e)\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  doBackgroundMask,\n",
    "  OUTPUT_PATH\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### inpaint fill\n",
    "\n",
    "inpaint an image by providing a subject and a mask. fill in the black part of the mask with a new generated image.\n",
    "\n",
    "inpaint mask?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const path = require('path')\n",
    "const {request} = require('gaxios')\n",
    "\n",
    "const OUTPUT_PATH = path.join(process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE, 'stable-diffusion-webui/outputs')\n",
    "\n",
    "async function doInpaintMask(image, mask, prompt) {\n",
    "  let width = 1024\n",
    "  \n",
    "  if(!prompt) {\n",
    "    // TODO: image 2 image with ollama vision?\n",
    "    return\n",
    "  }\n",
    "\n",
    "  if(prompt.includes('View360')) {\n",
    "    width = 2048\n",
    "  }\n",
    "\n",
    "  let base64_image\n",
    "  if(typeof image == 'string') {\n",
    "    if(image.startsWith('data:image/'))\n",
    "      image = image.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "  \n",
    "    if(image.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: image,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_image = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(image)) {\n",
    "      base64_image = Buffer.from(image, 'base64').toString('base64')\n",
    "    } else {\n",
    "      base64_image = fs.readFileSync(image).toString('base64')\n",
    "    }  \n",
    "  } else {\n",
    "    base64_image = image.toString('base64')\n",
    "  }\n",
    "\n",
    "  let base64_mask\n",
    "  if(typeof mask == 'string') {\n",
    "    if(mask.startsWith('data:image/'))\n",
    "      mask = mask.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "  \n",
    "    if(mask.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: mask,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_mask = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(mask)) {\n",
    "      base64_mask = Buffer.from(mask, 'base64').toString('base64')\n",
    "    } else {\n",
    "      base64_mask = fs.readFileSync(mask).toString('base64')\n",
    "    }  \n",
    "  } else {\n",
    "    base64_mask = mask.toString('base64')\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    let result = await request({\n",
    "      url: 'http://127.0.0.1:7860/sdapi/v1/img2img',\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json'\n",
    "      },\n",
    "      data: JSON.stringify({\n",
    "        prompt: prompt,\n",
    "        negative_prompt: 'bad hands, bad feet, bad faces, bad eyes, bad anatomy, extra limbs, missing limbs, tattoo, statue, picture frame, anime, cartoon, signature, abstract',\n",
    "        save_images: true,\n",
    "        \"width\": width,\n",
    "        \"height\": 1024,\n",
    "        \"steps\": 30,\n",
    "        tiling: false,\n",
    "        init_images: [base64_image],\n",
    "        //denoising_strength: 0.35,\n",
    "        mask: base64_mask,\n",
    "        mask_blur: 4,\n",
    "        inpainting_fill: 1,\n",
    "        inpaint_full_res: false,\n",
    "        inpaint_full_res_padding: 32,\n",
    "        inpainting_mask_invert: 1,\n",
    "      })\n",
    "    })\n",
    "    \n",
    "    let seed = JSON.parse(result.data.info).seed\n",
    "    let buff = Buffer.from(result.data.images[0], 'base64');\n",
    "    let now = new Date()\n",
    "    let folderName = now.getFullYear() + '-' + String(now.getMonth() + 1).padStart(2, '0') + '-' + String(now.getDate()).padStart(2, '0')\n",
    "    let stablePath = path.join(OUTPUT_PATH, 'img2img-images', folderName)\n",
    "    let imagePath\n",
    "    if(fs.existsSync(stablePath)) {\n",
    "      let images = fs.readdirSync(stablePath)\n",
    "      for(let i = 0; i < images.length; i++) {\n",
    "        if(images[i].match('-' + seed + '-')) {\n",
    "          imagePath = path.join('img2img-images', folderName, images[i])\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    return {seed, image: buff, imagePath, prompt}\n",
    "\n",
    "  } catch (e) {\n",
    "    console.error(e)\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  doInpaintMask,\n",
    "  OUTPUT_PATH\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### image2image\n",
    "\n",
    "convert the style of an input image to another image, add details, change painting styles.\n",
    "\n",
    "image 2 image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const path = require('path')\n",
    "const {request} = require('gaxios')\n",
    "\n",
    "const OUTPUT_PATH = path.join(process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE, 'stable-diffusion-webui/outputs')\n",
    "\n",
    "async function doImage2Image(image, prompt) {\n",
    "  let width = 1024\n",
    "  if(prompt.includes('View360')) {\n",
    "    width = 2048\n",
    "  }\n",
    "\n",
    "  let base64_image\n",
    "  if(typeof image == 'string') {\n",
    "    if(image.startsWith('data:image/'))\n",
    "      image = image.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "  \n",
    "    if(image.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: image,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_image = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(image)) {\n",
    "      base64_image = Buffer.from(image, 'base64').toString('base64')\n",
    "    } else {\n",
    "      base64_image = fs.readFileSync(image).toString('base64')\n",
    "    }  \n",
    "  } else {\n",
    "    base64_image = image.toString('base64')\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    let result = await request({\n",
    "      url: 'http://127.0.0.1:7860/sdapi/v1/img2img',\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json'\n",
    "      },\n",
    "      data: JSON.stringify({\n",
    "        prompt: prompt,\n",
    "        negative_prompt: 'bad hands, bad feet, bad faces, bad eyes, bad anatomy, extra limbs, missing limbs, tattoo, statue, picture frame, anime, cartoon, signature, abstract',\n",
    "        save_images: true,\n",
    "        \"width\": width,\n",
    "        \"height\": 1024,\n",
    "        \"steps\": 30,\n",
    "        tiling: false,\n",
    "        init_images: [base64_image],\n",
    "      })\n",
    "    })\n",
    "    \n",
    "    let seed = JSON.parse(result.data.info).seed\n",
    "    let buff = Buffer.from(result.data.images[0], 'base64');\n",
    "    let now = new Date()\n",
    "    let folderName = now.getFullYear() + '-' + String(now.getMonth() + 1).padStart(2, '0') + '-' + String(now.getDate()).padStart(2, '0')\n",
    "    let stablePath = path.join(OUTPUT_PATH, 'img2img-images', folderName)\n",
    "    let imagePath\n",
    "    if(fs.existsSync(stablePath)) {\n",
    "      let images = fs.readdirSync(stablePath)\n",
    "      for(let i = 0; i < images.length; i++) {\n",
    "        if(images[i].match('-' + seed + '-')) {\n",
    "          imagePath = path.join('img2img-images', folderName, images[i])\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    return {seed, image: buff, imagePath, prompt}\n",
    "\n",
    "  } catch (e) {\n",
    "    console.error(e)\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  doImage2Image,\n",
    "  OUTPUT_PATH\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### google whisk\n",
    "\n",
    "combine multiple images and vision prompts into a single output image, select a subject, a scene, and an art style to whisk together.\n",
    "\n",
    "whisk images?\n",
    "\n",
    "TODO: center the subject using the center of white and crop to be square so it doesn't distort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const { request } = require('gaxios')\n",
    "const requestOllamaVision = importer.import('request ollama vision')\n",
    "const selectModel = importer.import('select llm')\n",
    "const {doStableRequest} = importer.import('stable diffusion request')\n",
    "const {doImage2Image} = importer.import('image 2 image')\n",
    "const {doBackgroundMask} = importer.import('mask image')\n",
    "const {doInpaintMask} = importer.import('inpaint mask')\n",
    "// TODO: use the above functions in combination to whisk together a set of images\n",
    "\n",
    "async function whiskImages(subject, scene, style, short) {\n",
    "  let promptModel = await selectModel(process.env.DEFAULT_MODEL || 'Default')\n",
    "\n",
    "  let subjectString\n",
    "  let subjectShort\n",
    "  let base64_subject\n",
    "  if(typeof subject == 'string') {\n",
    "    if(subject.startsWith('data:image/')) {\n",
    "      subject = subject.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "      base64_subject = Buffer.from(subject, 'base64').toString('base64')\n",
    "    } else if(subject.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: subject,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_subject = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(subject)) {\n",
    "      subjectString = subject\n",
    "    } else {\n",
    "      base64_subject = fs.readFileSync(subject).toString('base64')\n",
    "    }  \n",
    "  } else if(subject) {\n",
    "    base64_subject = subject.toString('base64')\n",
    "  }\n",
    "\n",
    "\n",
    "  let sceneString\n",
    "  let sceneShort\n",
    "  let base64_scene\n",
    "  if(typeof scene == 'string') {\n",
    "    if(scene.startsWith('data:image/')) {\n",
    "      scene = scene.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "      base64_scene = Buffer.from(scene, 'base64').toString('base64')\n",
    "    } else if(scene.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: scene,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_scene = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(scene)) {\n",
    "      sceneString = scene\n",
    "    } else {\n",
    "      base64_scene = fs.readFileSync(scene).toString('base64')\n",
    "    }  \n",
    "  } else if (scene) {\n",
    "    base64_scene = scene.toString('base64')\n",
    "  }\n",
    "\n",
    "\n",
    "  let styleString\n",
    "  let styleShort\n",
    "  let base64_style\n",
    "  if(typeof style == 'string') {\n",
    "    if(style.startsWith('data:image/')) {\n",
    "      style = style.replace(/^data:image\\/.*?;base64,/gi, '')\n",
    "      base64_style = Buffer.from(style, 'base64').toString('base64')\n",
    "    } else if(style.includes('://')) {\n",
    "      let result = await request({\n",
    "        url: style,\n",
    "        method: 'GET',\n",
    "      })\n",
    "      base64_style = Buffer.from(await result.data.arrayBuffer()).toString('base64')\n",
    "    } else if (!fs.existsSync(style)) {\n",
    "      styleString = style\n",
    "    } else {\n",
    "      base64_style = fs.readFileSync(style).toString('base64')\n",
    "    }  \n",
    "  } else if(style) {\n",
    "    base64_style = style.toString('base64')\n",
    "  }\n",
    "\n",
    "  // TODO: if passing in an image, ask ollama vision for a description, \n",
    "  //   if passing in a description use it to generate the next image\n",
    "  if(!subjectString && base64_subject) {\n",
    "    subjectString = await requestOllamaVision('data:image/png;base64,' + base64_subject, 'Describe the foreground subject of the image in one short sentence.')\n",
    "  }\n",
    "  if(short && subjectString) {\n",
    "    subjectShort = await promptModel('Summarize this sentence into four or five words:\\n' + subjectString + '\\nOnly return the summary, no title or explanation.')\n",
    "  }\n",
    "\n",
    "  if(!sceneString && base64_scene) {\n",
    "    sceneString = await requestOllamaVision('data:image/png;base64,' + base64_scene, 'Describe the scenery in the image in one short sentence.')\n",
    "  }\n",
    "  if(short && sceneString) {\n",
    "    sceneShort = await promptModel('Summarize this sentence into four or five words:\\n' + sceneString + '\\nOnly return the summary, no title or explanation.')\n",
    "  }\n",
    "\n",
    "  if(!styleString && base64_style) {\n",
    "    styleString = await requestOllamaVision('data:image/png;base64,' + base64_style, 'Describe the art style of image in one short sentence.')\n",
    "  }\n",
    "  if(short && styleString) {\n",
    "    styleShort = await promptModel('Summarize this sentence into four or five words:\\n' + styleString + '\\nOnly return the summary, no title or explanation.')\n",
    "  }\n",
    "\n",
    "  // TODO: if no scene, only subject and style, then just call image 2 image\n",
    "  if(!base64_scene && !base64_style && !base64_subject) {\n",
    "    // no images passed in, send directly to image generator\n",
    "    if(short)\n",
    "      return await doStableRequest(subjectShort + '\\n' + sceneShort + '\\n' + styleShort)\n",
    "    else\n",
    "      return await doStableRequest(subjectString + '\\n' + sceneString + '\\n' + styleString)\n",
    "  } else if (base64_subject && !sceneString) {\n",
    "    // subject and style process only, pass directly to image 2 image\n",
    "    if(short)\n",
    "      return await doImage2Image('data:image/png;base64,' + base64_subject, subjectShort + (styleShort ? ('\\n' + styleShort) : ''))\n",
    "    else\n",
    "      return await doImage2Image('data:image/png;base64,' + base64_subject, subjectString + (styleString ? ('\\n' + styleString) : ''))\n",
    "  } else if (base64_scene && !subjectString) {\n",
    "    // scene and style only, pass to image 2 image\n",
    "    if(short)\n",
    "      return await doImage2Image('data:image/png;base64,' + base64_scene, sceneShort + (styleShort ? ('\\n' + styleShort) : ''))\n",
    "    else\n",
    "      return await doImage2Image('data:image/png;base64,' + base64_scene, sceneString + (styleString ? ('\\n' + styleString) : ''))\n",
    "  } else if (base64_subject && sceneString) {\n",
    "    // TODO: extract mask on subject\n",
    "    let maskObject = await doBackgroundMask('data:image/png;base64,' + base64_subject)\n",
    "    let base64_mask = maskObject.image.toString('base64')\n",
    "\n",
    "    // TODO: combine subject with new scene\n",
    "    let inpaintObject\n",
    "    if(short)\n",
    "      inpaintObject = await doInpaintMask(\n",
    "        'data:image/png;base64,' + base64_subject, \n",
    "        'data:image/png;base64,' + base64_mask, \n",
    "        sceneShort)\n",
    "    else\n",
    "      inpaintObject = await doInpaintMask(\n",
    "        'data:image/png;base64,' + base64_subject, \n",
    "        'data:image/png;base64,' + base64_mask, \n",
    "        sceneString)\n",
    "    \n",
    "    // Drop out early if there is no style specified, just do the proper inpainting\n",
    "    if(!styleString) {\n",
    "      return inpaintObject\n",
    "    }\n",
    "\n",
    "    let base64_inpaint = inpaintObject.image.toString('base64')\n",
    "    \n",
    "\n",
    "    // TODO: generate final image in new style\n",
    "    if(short)\n",
    "      return await doImage2Image('data:image/png;base64,' + base64_inpaint, styleShort + '\\n' + subjectShort + '\\n' + sceneShort)\n",
    "    else\n",
    "      return await doImage2Image('data:image/png;base64,' + base64_inpaint, styleString + '\\n' + subjectString + '\\n' + sceneString)\n",
    "  } else {\n",
    "    console.error('Missing components: ')\n",
    "    return {}\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = whiskImages\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
