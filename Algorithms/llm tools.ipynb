{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "how to scan sqlite tools?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "how to scan chat logs?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "//import {fileURLToPath} from \"url\";\n",
    "const fs = require('fs')\n",
    "const path = require('path')\n",
    "const importNotebook = importer.import\n",
    "const {askLlamaAboutEmotions} = importNotebook('ask llm about emotions')\n",
    "const {storeChatHistory} = importNotebook('how to cache chat logs')\n",
    "const { chatCache } = importer.import('cache chat history with llm descriptions')\n",
    "const { askLlamaAboutConversation, askLlamaAboutCategory } = importNotebook('ask llm about chat conversations')\n",
    "\n",
    "const hashCode = s => s.split('').reduce((a,b) => (((a << 5) - a) + b.charCodeAt(0))|0, 0)\n",
    "\n",
    "const CHAT_DIRECTORIES = [\n",
    "  '/Volumes/External/Personal/Collections/conversations',\n",
    "  '/Volumes/External/Personal/Collections/conversations/Trillian/logs/AIM/Query',\n",
    "  '/Volumes/External/Personal/Collections/conversations/Trillian/logs/MSN/Query',\n",
    "  '/Volumes/External/Personal/Collections/conversations/Trillian/logs/old logs/AIM',\n",
    "  '/Volumes/External/Personal/Collections/conversations/Trillian/logs/old logs/MSN',\n",
    "]\n",
    "\n",
    "const CHAT_DATES = [\n",
    "  /(January|February|March|April|May|June|July|August|September|October|November|December) (\\d{1,2}), \\d{4}/,\n",
    "  /(0[1-9]|[12]\\d|3[01])\\.(0[1-9]|1[0-2])\\.\\d{4}/,\n",
    "  /(0[1-9]|1[0-2])\\/(0[1-9]|[12]\\d|3[01])\\/\\d{4}/,\n",
    "  /\\d{4}-(0[1-9]|1[0-2])-(0[1-9]|[12]\\d|3[01])/,\n",
    "  /(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) (\\d{1,2}), \\d{4}/\n",
    "]\n",
    "\n",
    "const CHAT_TIMES = [\n",
    "  /(0[1-9]|1[0-2]):([0-5]\\d):([0-5]\\d)\\s?(AM|PM)/i,\n",
    "  /([01]\\d|2[0-3]):([0-5]\\d):([0-5]\\d)/,\n",
    "  /(0[1-9]|1[0-2]):([0-5]\\d)\\s?(AM|PM)/i,\n",
    "  /([01]\\d|2[0-3]):([0-5]\\d)/\n",
    "]\n",
    "\n",
    "async function askLlamaAboutChatLog(chatLog) {\n",
    "  if(!chatLog) {\n",
    "    chatLog = 'anti_milestone@hotmail.com'\n",
    "  }\n",
    "\n",
    "  let chatHistory = []\n",
    "  let chatPath\n",
    "  for(let i = 0; i < CHAT_DIRECTORIES.length; i++) {\n",
    "    chatPath = path.join(CHAT_DIRECTORIES[i], chatLog + '.log')\n",
    "    if(fs.existsSync(chatPath)) {\n",
    "      chatHistory = fs.readFileSync(chatPath).toLocaleString('utf-8').split('\\n')\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "\n",
    "  let mtime = fs.statSync(chatPath).mtime.getTime()\n",
    "  let cellCounter = 0\n",
    "  let currentMessages = []\n",
    "  let currentTotal = 0\n",
    "  let cellId = chatPath + '[' + cellCounter + ']'\n",
    "  for(let i = 0; i < chatHistory.length; i++) {\n",
    "    if(currentMessages.length > 0 && currentTotal + chatHistory[i].length > 2048 || currentMessages.length == 20) {\n",
    "      // process now\n",
    "      // TODO: store result\n",
    "      let messageBlock = currentMessages.join('\\n')\n",
    "      let date = CHAT_DATES.map(d => (messageBlock.match(d) || [])[0]).filter(d=>d)[0]\n",
    "      let time = CHAT_TIMES.map(d => (messageBlock.match(d) || [])[0]).filter(d=>d)[0]\n",
    "      let now = new Date(date + ' ' + time).getTime()\n",
    "      let hash = hashCode(messageBlock)\n",
    "      if(typeof chatCache[cellId] == 'undefined'\n",
    "        || chatCache[cellId].hash != hash\n",
    "        || typeof chatCache[cellId].emotions == 'undefined'\n",
    "        || typeof chatCache[cellId].category != 'string'\n",
    "        || typeof chatCache[cellId].date == 'undefined'\n",
    "        || !chatCache[cellId].date\n",
    "        || chatCache[cellId].summary.match(/Find the derivative/gi)\n",
    "        || chatCache[cellId].category == '<h1>'\n",
    "      ) {\n",
    "        let summary = await askLlamaAboutConversation(currentMessages)\n",
    "        let emotions = await askLlamaAboutEmotions(currentMessages)\n",
    "        let category = await askLlamaAboutCategory(currentMessages)\n",
    "        storeChatHistory(cellId, mtime, summary, emotions, category, hash, now)\n",
    "      }\n",
    "      currentMessages = []\n",
    "      currentTotal = 0\n",
    "      cellCounter++\n",
    "      cellId = chatPath + '[' + cellCounter + ']'\n",
    "    }\n",
    "\n",
    "    currentMessages[currentMessages.length] = chatHistory[i]\n",
    "    currentTotal += chatHistory[i].length\n",
    "  }\n",
    "  if(currentMessages.length > 0) {\n",
    "    // process now\n",
    "    let messageBlock = currentMessages.join('\\n')\n",
    "    let date = CHAT_DATES.map(d => (messageBlock.match(d) || [])[0]).filter(d=>d)[0]\n",
    "    let time = CHAT_TIMES.map(d => (messageBlock.match(d) || [])[0]).filter(d=>d)[0]\n",
    "    let now = new Date(date + ' ' + time).getTime()\n",
    "    let hash = hashCode(messageBlock)\n",
    "    if(typeof chatCache[cellId] == 'undefined'\n",
    "      || chatCache[cellId].hash != hash\n",
    "      || typeof chatCache[cellId].emotions == 'undefined'\n",
    "      || typeof chatCache[cellId].category != 'string'\n",
    "      || typeof chatCache[cellId].date == 'undefined'\n",
    "    ) {\n",
    "      let summary = await askLlamaAboutConversation(currentMessages)\n",
    "      let emotions = await askLlamaAboutEmotions(currentMessages)\n",
    "      let category = await askLlamaAboutCategory(currentMessages)\n",
    "      storeChatHistory(cellId, mtime, summary, emotions, category, hash, now)\n",
    "    }\n",
    "    // TODO: store result\n",
    "  }\n",
    "\n",
    "  \n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  askLlamaAboutChatLog,\n",
    "  askLlamaAboutConversation\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ask llm about emotions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const llama = importer.import('create llm session')\n",
    "\n",
    "const EMOTIONS = [\n",
    "  'Joyful',\n",
    "  'Romantic',\n",
    "  'Angry',\n",
    "  'Confused',\n",
    "  'Supportive',\n",
    "  'Excited',\n",
    "  'Nostalgic',\n",
    "  'Grateful',\n",
    "  'Sad',\n",
    "  'Humorous',\n",
    "  'Anxious',\n",
    "  'Curious',\n",
    "  'Inspired',\n",
    "  'Defensive',\n",
    "  'Assertive',\n",
    "  'Empathetic',\n",
    "  'Reflective',\n",
    "  'Playful',\n",
    "  'Hopeful',\n",
    "  'Apologetic',\n",
    "  'Lonely',\n",
    "  'Proud',\n",
    "  'Vulnerable',\n",
    "  'Determined',\n",
    "  'Aroused',\n",
    "  'Neutral',\n",
    "  'Dissident',\n",
    "  'Rebelious',\n",
    "  'Frustrated',\n",
    "  'Helpful'\n",
    "]\n",
    "\n",
    "const EMOTION_HEX = [\n",
    "  '#FFFF00',\n",
    "  '#FFC0CB',\n",
    "  '#FF0000',\n",
    "  '#D8BFD8',\n",
    "  '#90EE90',\n",
    "  '#FFA500',\n",
    "  '#4682B4',\n",
    "  '#FFD700',\n",
    "  '#00008B',\n",
    "  '#FFFF99',\n",
    "  '#800080',\n",
    "  '#40E0D0',\n",
    "  '#FFC107',\n",
    "  '#800000',\n",
    "  '#FF4500',\n",
    "  '#E6E6FA',\n",
    "  '#B0C4DE',\n",
    "  '#00FFFF',\n",
    "  '#FFFACD',\n",
    "  '#B0E0E6',\n",
    "  '#191970',\n",
    "  '#FFD700',\n",
    "  '#FFE4E1',\n",
    "  '#DC143C'\n",
    "]\n",
    "\n",
    "async function askLlamaAboutEmotions(currentMessages, session) {\n",
    "  const {llmPrompt} = (await llama)\n",
    "  if(typeof currentMessages == 'string') {\n",
    "    currentMessages = [currentMessages]\n",
    "  }\n",
    "\n",
    "  let q1 = 'Can you derive the emotional contexts of this conversation:\\n' + \n",
    "  currentMessages.join('\\n') + '\\nOnly give the emotion in the response.'\n",
    "  console.log(\"User: \" + q1);\n",
    "  const a1 = await llmPrompt(q1);\n",
    "  console.log(\"AI: \" + a1);\n",
    "\n",
    "  let q2 = 'Based on this description which emotion best fits:\\n' + \n",
    "    a1 + '\\nOut of this list of emotions which one is the closest match:' +\n",
    "    EMOTIONS.join(', ') + '\\nOnly respond with the matching emotion.'\n",
    "  console.log(\"User: \" + q2);\n",
    "  const a2 = await llmPrompt(q2);\n",
    "  console.log(\"AI: \" + a2);\n",
    "  let emotions = a2.trim().split(/\\n|,\\s*|\\s*- |\\s*\\* /gi)\n",
    "\n",
    "  console.log(emotions)\n",
    "  return EMOTIONS.filter(e => emotions.includes(e))[0]\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  askLlamaAboutEmotions,\n",
    "  EMOTIONS,\n",
    "  EMOTION_HEX\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "how to cache chat logs?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const { chatCache } = importer.import('cache chat history with llm descriptions')\n",
    "const { updateCode } = importer.import('update code cell')\n",
    "\n",
    "function storeChatHistory (cellId, mtime, summary, emotions, category, hash, date) {\n",
    "  chatCache[cellId] = {\n",
    "    mtime,\n",
    "    summary,\n",
    "    emotions,\n",
    "    category,\n",
    "    hash,\n",
    "    date\n",
    "  }\n",
    "  var code = `\n",
    "// cell cache automatically replaced\n",
    "var chatCache = ${JSON.stringify(chatCache, null, 4)}\n",
    "\n",
    "module.exports = {\n",
    "  chatCache\n",
    "}\n",
    "`\n",
    "  var cacheCell = importer.interpret('cache chat history with llm descriptions')\n",
    "  updateCode(cacheCell, code)\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  storeChatHistory\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ask llm about chat conversations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const llama = importer.import('create llm session')\n",
    "\n",
    "async function askLlamaAboutConversation(currentMessages) {\n",
    "  const {llmPrompt} = (await llama)\n",
    "  let q1 = 'Can you summarize in two sentences what this conversation is about:\\n' + \n",
    "  currentMessages.join('\\n') + '\\nPlease discard any pleasantries, documentation only.'\n",
    "  console.log(\"User: \" + q1);\n",
    "  const a1 = await llmPrompt(q1);\n",
    "  console.log(\"AI: \" + a1);\n",
    "  return a1.trim()\n",
    "}\n",
    "\n",
    "async function askLlamaAboutCategory(currentMessages) {\n",
    "  const {llmPrompt} = (await llama)\n",
    "  let q1 = 'Categorize this conversation in two or three words:\\n' + \n",
    "  currentMessages.join('\\n') + '\\nOnly respond with the category.'\n",
    "  console.log(\"User: \" + q1);\n",
    "  const a1 = await llmPrompt(q1);\n",
    "  console.log(\"AI: \" + a1);\n",
    "  return a1.trim().split(/\\n|,\\s*|\\s*- |\\s*\\* /gi)[0]\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  askLlamaAboutConversation,\n",
    "  askLlamaAboutCategory\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "how to scan code history?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "how to scan calendar journal entries?\n",
    "\n",
    "how to ask if my theories are correct?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "javascript"
  },
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "14.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
