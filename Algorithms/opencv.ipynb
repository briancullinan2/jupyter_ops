{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open CV\n",
    "\n",
    "TODO: create security cameras\n",
    "\n",
    "TODO: create a Google VR app that allows you to type on any surface using the front camera\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "detect people?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import_notebook('motion detection', globals())\n",
    "\n",
    "\n",
    "# Initialize HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "def get_image(image_path):\n",
    "\n",
    "  # Load image\n",
    "  if os.path.exists(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "  else:\n",
    "    # Fetch the image from the URL\n",
    "    response = requests.get(image_path)\n",
    "    response.raise_for_status()  # Raise an error if the request fails\n",
    "\n",
    "    # Convert to a NumPy array for OpenCV\n",
    "    image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "  # Resize image (optional, improves detection speed)\n",
    "  image = cv2.resize(image, (800, 600))\n",
    "\n",
    "  return image\n",
    "\n",
    "def trace_boxes(image_path):\n",
    "\n",
    "  if isinstance(image_path, str):\n",
    "    image = get_image(image_path)\n",
    "  else:\n",
    "    image = image_path\n",
    "\n",
    "  # Convert to grayscale (not necessary, but can improve performance)\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Detect people\n",
    "  boxes, weights = hog.detectMultiScale(gray, winStride=(4, 4), padding=(8, 8), scale=1.05)\n",
    "\n",
    "  return boxes\n",
    "\n",
    "def trace_people(image_path):\n",
    "\n",
    "  if isinstance(image_path, str):\n",
    "    image = get_image(image_path)\n",
    "  else:\n",
    "    image = image_path\n",
    "\n",
    "  boxes = trace_boxes(image)\n",
    "\n",
    "  # Draw bounding boxes\n",
    "  for (x, y, w, h) in boxes:\n",
    "      cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "  return image\n",
    "\n",
    "def main(image_path):\n",
    "  prev_frame = None\n",
    "  image = None\n",
    "  while True:\n",
    "    # Create a random image (or load a new one dynamically)\n",
    "    image = get_image(image_path)\n",
    "\n",
    "    if(prev_frame is not None):\n",
    "      frame = image_grayscale(image)\n",
    "      image = diff_images(prev_frame, frame)\n",
    "      motion = percent_motion(image)\n",
    "      # TODO: if motion is > 1.0 start recording and compile a video and upload to youtube\n",
    "      print(motion)\n",
    "    else:\n",
    "      frame = image_grayscale(image)\n",
    "      image = trace_people(image)  # Random image example\n",
    "\n",
    "    prev_frame = frame.copy()\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow(\"People Detection\", image)\n",
    "\n",
    "    # Wait for 1 second (1000 ms) and check for key press\n",
    "    if cv2.waitKey(1000) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "__all__ = {\n",
    "  \"main\": main,\n",
    "  \"trace_people\": trace_people\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "motion detection?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def percent_motion(thresh):\n",
    "  white_pixels = np.count_nonzero(thresh == 255)\n",
    "  total_pixels = thresh.size\n",
    "\n",
    "  # Calculate percentage\n",
    "  white_percentage = (white_pixels / total_pixels) * 100\n",
    "  return white_percentage\n",
    "\n",
    "def image_grayscale(image):\n",
    "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  return gray_image\n",
    "\n",
    "def diff_images(prev_frame, frame):\n",
    "  # Compute absolute difference between current and previous frame\n",
    "  diff = cv2.absdiff(prev_frame, frame)\n",
    "\n",
    "  # Threshold the difference image\n",
    "  _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "  # Update previous frame\n",
    "  # prev_frame = frame.copy()\n",
    "  return thresh\n",
    "\n",
    "__all__ = {\n",
    "  \"percent_motion\": percent_motion,\n",
    "  \"image_grayscale\": image_grayscale,\n",
    "  \"diff_images\": diff_images\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "python write video?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Set output video properties\n",
    "fps = 30\n",
    "output_file = \"output.mp4\"\n",
    "\n",
    "def write_video():\n",
    "  # Get list of images\n",
    "  image_files = sorted(glob.glob(\"frame_*.jpg\"))  # Adjust pattern as needed\n",
    "\n",
    "  # Read first image to get dimensions\n",
    "  frame = cv2.imread(image_files[0])\n",
    "  height, width, _ = frame.shape\n",
    "\n",
    "  # Define VideoWriter object\n",
    "  fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec\n",
    "  out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "  # Write images to video\n",
    "  for img_path in image_files:\n",
    "      frame = cv2.imread(img_path)\n",
    "      out.write(frame)\n",
    "\n",
    "  # Cleanup\n",
    "  out.release()\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "__all__ = {\n",
    "  \"write_video\": write_video\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "python write images to ffmpeg stream?\n",
    "\n",
    "ffmpeg -i http://192.168.4.22:8080/video -i http://192.168.4.22:8080/audio.wav -c:v libx264 -preset ultrafast -b:v 4500k -maxrate 4500k -bufsize 9000k -g 50 -c:a aac -b:a 128k -ar 44100 -f flv rtmp://a.rtmp.youtube.com/live2/dvqv-7eyf-72d5-vaw7-dvsb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import subprocess\n",
    "import time\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "\n",
    "# Take a screenshot and save it to a file\n",
    "screenshot = pyautogui.screenshot()\n",
    "\n",
    "width, height = screenshot.size\n",
    "\n",
    "# Video properties\n",
    "#width, height, fps = 1280, 720, 30\n",
    "fps = 4\n",
    "\n",
    "# FFmpeg command for encoding & saving video\n",
    "ffmpeg_cmd = [\n",
    "    \"ffmpeg\",\n",
    "    \"-y\",\n",
    "    \"-f\", \"image2pipe\",\n",
    "    \"-vcodec\", \"mjpeg\",\n",
    "    \"-r\", str(fps),\n",
    "    \"-i\", \"-\",  # Read from stdin\n",
    "    \"-c:v\", \"libx264\",\n",
    "    \"-preset\", \"ultrafast\",\n",
    "    \"-b:v\", \"4500k\",\n",
    "    \"-maxrate\", \"4500k\",\n",
    "    \"-bufsize\", \"9000k\",\n",
    "    \"-g\", \"50\",\n",
    "    \"-f\", \"flv\",\n",
    "    \"rtmp://a.rtmp.youtube.com/live2/dvqv-7eyf-72d5-vaw7-dvsb\"\n",
    "]\n",
    "\n",
    "def stream_images(images):\n",
    "\n",
    "  # Start FFmpeg process\n",
    "  process = subprocess.Popen(ffmpeg_cmd, stdin=subprocess.PIPE)\n",
    "\n",
    "  # OpenCV VideoWriter (encoding to a memory buffer)\n",
    "  # fourcc = cv2.VideoWriter_fourcc(*\"H264\")\n",
    "  # video_writer = cv2.VideoWriter(process.stdin, fourcc, fps, (width, height))\n",
    "\n",
    "  # OpenCV video capture\n",
    "  #cap = cv2.VideoCapture(0)\n",
    "\n",
    "  try:\n",
    "    while True:\n",
    "      #ret, frame = cap.read()\n",
    "      #if not ret:\n",
    "      #    break\n",
    "      screenshot = pyautogui.screenshot()\n",
    "      screenshot_np = np.array(screenshot)\n",
    "\n",
    "      # Convert RGB to BGR (OpenCV uses BGR format)\n",
    "      screenshot_cv = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "      _, jpeg_bytes = cv2.imencode(\".jpg\", screenshot_cv, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "\n",
    "      # Write frame to OpenCV VideoWriter\n",
    "      # video_writer.write(screenshot_cv)\n",
    "\n",
    "      # Get encoded frame and send to FFmpeg\n",
    "      process.stdin.write(jpeg_bytes.tobytes())\n",
    "\n",
    "      time.sleep(1 / fps / 2)\n",
    "\n",
    "      # Get encoded frame and send to FFmpeg\n",
    "      process.stdin.write(jpeg_bytes.tobytes())\n",
    "\n",
    "      time.sleep(1 / fps / 2)\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "    print(\"\\nCTRL+C detected. Exiting...\")\n",
    "  # Cleanup\n",
    "  # cap.release()\n",
    "  video_writer.release()\n",
    "  process.stdin.close()\n",
    "  process.wait()\n",
    "\n",
    "__all__ = {\n",
    "  \"stream_images\": stream_images\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "10.16.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
