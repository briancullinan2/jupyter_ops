{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d658c6fd",
   "metadata": {},
   "source": [
    "\n",
    "list wikimedia articles?\n",
    "\n",
    "ROUTE = /wikimedia-search.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84087e47",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const readIndex = importer.import('load wikimedia index')\n",
    "\n",
    "let allTitles = []\n",
    "\n",
    "\n",
    "async function readWikimedia(search) {\n",
    "\n",
    "  let matches = []\n",
    "  if(search) {\n",
    "    search = search.toLocaleLowerCase().split(/,|\\s+/)\n",
    "  }\n",
    "\n",
    "  // use memory cache\n",
    "  if (allTitles.length) {\n",
    "    for (let i = 0; i < allTitles.length; i++) {\n",
    "      let match = search.filter(s => allTitles[i].title.includes(s)).length\n",
    "      if (search && match >= search.length - 1 && match > 0) {\n",
    "        console.log('match found in set:', search, allTitles[i].title)\n",
    "        matches.push(allTitles[i])\n",
    "      }\n",
    "    }\n",
    "    return matches\n",
    "  }\n",
    "\n",
    "  // === Step 3: Tie it all together ===\n",
    "  await new Promise(resolve => readIndex(search, ({ offset, length }, titles, finished) => {\n",
    "    console.log('reading index:', finished, titles[0])\n",
    "    for (let i = 0; i < titles.length; i++) {\n",
    "      allTitles.push({ offset, length, title: titles[i] })\n",
    "      let match = search.filter(s => titles[i].includes(s)).length \n",
    "      if (search && match >= search.length - 1 && match > 0) {\n",
    "        console.log('match found in set:', search, titles[i])\n",
    "        matches.push({ offset, length, title: titles[i] })\n",
    "      }\n",
    "    }\n",
    "\n",
    "    if (finished === true) {\n",
    "      resolve()\n",
    "    }\n",
    "  }));\n",
    "\n",
    "  return matches\n",
    "\n",
    "}\n",
    "\n",
    "module.exports = readWikimedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3636d0a",
   "metadata": {},
   "source": [
    "\n",
    "load wikimedia index?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251cbb0",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs');\n",
    "const path = require('path')\n",
    "//const zlib = require('zlib');\n",
    "\n",
    "const INDEX_FILE = path.join(process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE, 'Downloads', 'enwiki-20250420-pages-articles-multistream-index.txt')\n",
    "const XML_FILE = path.join(process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE, 'Downloads', 'enwiki-20250420-pages-articles-multistream.xml.bz2')\n",
    "\n",
    "function readIndex(search, callback) {\n",
    "  const length = fs.statSync(INDEX_FILE).size\n",
    "  const stream = fs.createReadStream(INDEX_FILE, {\n",
    "    highWaterMark: 64 * 1024,\n",
    "  });\n",
    "  let lastOffset\n",
    "  let leftover = ''\n",
    "  let lastTitles = []\n",
    "  let offsetCount = 0\n",
    "  stream.on('data', chunk => {\n",
    "    offsetCount += chunk.length\n",
    "    const lines = (leftover + chunk.toString()).split('\\n');\n",
    "    leftover = lines.pop();\n",
    "    for (const line of lines) {\n",
    "      const [offsetStr, pageId, title] = line.split(':');\n",
    "      const currentOffset = parseInt(offsetStr)\n",
    "      if (currentOffset && currentOffset !== lastOffset) {\n",
    "        if (lastOffset) {\n",
    "          callback({ length: currentOffset - lastOffset, offset: lastOffset }, lastTitles, offsetCount / length * 100.0);\n",
    "        }\n",
    "        lastOffset = currentOffset\n",
    "        lastTitles = []\n",
    "      }\n",
    "      lastTitles.push(title.toLocaleLowerCase())\n",
    "    }\n",
    "  });\n",
    "\n",
    "  stream.on('end', () => {\n",
    "    callback({ length: fs.statSync(XML_FILE).size - lastOffset, offset: lastOffset }, lastTitles, true);\n",
    "  });\n",
    "}\n",
    "\n",
    "module.exports = readIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e475b",
   "metadata": {},
   "source": [
    "\n",
    "extract wikimedia chunk?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f9c46",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs');\n",
    "const path = require('path')\n",
    "//const zlib = require('zlib');\n",
    "const { PassThrough, Transform } = require('stream');\n",
    "const XmlStream = require('xml-stream');\n",
    "const bz2 = require('unbzip2-stream');\n",
    "\n",
    "const XML_FILE = path.join(process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE, 'Downloads', 'enwiki-20250420-pages-articles-multistream.xml.bz2')\n",
    "\n",
    "// Extract and parse one chunk\n",
    "function extractChunk(startOffset, endOffset, callback) {\n",
    "  console.log('reading:', startOffset, endOffset)\n",
    "  const fileStream = fs.createReadStream(XML_FILE, {\n",
    "    start: startOffset,\n",
    "    end: endOffset - 1 // end is inclusive\n",
    "  });\n",
    "\n",
    "  const decompress = bz2();\n",
    "\n",
    "  // 2. Create a Transform stream to replace `\\n`\n",
    "  const normalizeNewlines = new Transform({\n",
    "    decodeStrings: false,\n",
    "    transform(chunk, encoding, callback) {\n",
    "      // Replace or remove newlines here:\n",
    "      const text = chunk.toString().replace(/\\n/g, '&lt;br /&gt;'); // or replace(/\\n/g, ' ')\n",
    "      this.push(text);\n",
    "      callback();\n",
    "    }\n",
    "  });\n",
    "  \n",
    "  // 3. Compose stream: wrapperStart + transformed decompressed + wrapperEnd\n",
    "  const wrapperStart = new PassThrough();\n",
    "  wrapperStart.end('<mediawiki>');\n",
    "  \n",
    "  const wrapperEnd = new PassThrough();\n",
    "  wrapperEnd.end('</mediawiki>');\n",
    "  \n",
    "  const decompressedStream = fileStream.pipe(decompress).pipe(normalizeNewlines);\n",
    "  \n",
    "  const fullStream = new PassThrough();\n",
    "  wrapperStart.pipe(fullStream, { end: false });\n",
    "  decompressedStream.pipe(fullStream, { end: false });\n",
    "  decompressedStream.on('end', () => {\n",
    "    wrapperEnd.pipe(fullStream);\n",
    "  });\n",
    "  \n",
    "  // 4. Pipe into XmlStream\n",
    "  const xml = new XmlStream(fullStream);\n",
    "\n",
    "  xml.preserve('text'); // This is a key part\n",
    "  xml.collect('text');\n",
    "  \n",
    "  xml.on('endElement: page', page => {\n",
    "    //console.log(`Title: ${page.title}`);\n",
    "    callback(page)\n",
    "  });\n",
    "\n",
    "  xml.on('end', () => {\n",
    "    console.log(`Chunk finished\\n`);\n",
    "    callback(false);\n",
    "  });\n",
    "\n",
    "  xml.on('error', err => {\n",
    "    console.error('XML error:', err);\n",
    "  });\n",
    "\n",
    "  decompress.on('error', err => {\n",
    "    console.error('BZ2 decompression error:', err);\n",
    "  });\n",
    "}\n",
    "\n",
    "module.exports = extractChunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ebbaf",
   "metadata": {},
   "source": [
    "\n",
    "wikimedia-page.html?\n",
    "\n",
    "ROUTE = /wikimedia-page.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19ee42",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const extractChunk = importer.import('extract wikimedia chunk')\n",
    "const preprocessDoc = importer.import('mediawiki text preprocessor')\n",
    "//const wtf = require('wtf_wikipedia')\n",
    "const Mustache = require('mustache');\n",
    "//const parsoid = require('parsoid');\n",
    "\n",
    "async function extractWikimedia(offset, length, search) {\n",
    "  if (!search) {\n",
    "    throw new Error('Page not found.')\n",
    "  }\n",
    "  let markdown = ''\n",
    "  let xmlPage\n",
    "  offset = parseInt(offset)\n",
    "  length = parseInt(length)\n",
    "  try {\n",
    "    await new Promise(resolve => extractChunk(offset, offset + length, page => {\n",
    "      if (page === false) {\n",
    "        return resolve()\n",
    "      }\n",
    "\n",
    "      if (page.title.toLocaleLowerCase().includes(search.toLocaleLowerCase())) {\n",
    "        //console.log(page.revision.text[0]['$children'].slice(100))\n",
    "        xmlPage = page\n",
    "        markdown = page.revision.text[0]['$children'].join('').replaceAll('<br />', '\\n') // for parsing\n",
    "      }\n",
    "    }))\n",
    "\n",
    "    //let doc = wtf()\n",
    "    let template = importer.interpret('wikimedia mustache template').code\n",
    "    //console.log(markdown)\n",
    "    fs.writeFileSync(__dirname + '/../test.md', markdown)\n",
    "    const preprocessed = preprocessDoc(markdown);\n",
    "    const content = Mustache.render(template, Object.assign({\n",
    "      title: xmlPage.title\n",
    "    }, preprocessed)); //await wikitextToHTML(markdown)\n",
    "    const html = Mustache.render(importer.interpret('wikiemedia clone index').code, {\n",
    "      content: content,\n",
    "      TIMESTAMP: Date.now()\n",
    "    });\n",
    "    return html\n",
    "  } catch (e) {\n",
    "    throw e\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "module.exports = extractWikimedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a57f25",
   "metadata": {},
   "source": [
    "\n",
    "mediawiki text preprocessor?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73220c32",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const balanced = importer.import('balanced')\n",
    "const Mustache = require('mustache');\n",
    "const { Remarkable } = require('remarkable');\n",
    "const md = new Remarkable({ html: true, xhtmlOut: true, breaks: true });\n",
    "\n",
    "function preprocessDoc(wikiText) {\n",
    "  //const templateMatcher = /\\{\\{\\s*(#?[a-zA-Z0-9_]+)(.*?)\\}\\}/gs;\n",
    "  let remaining = wikiText\n",
    "  let count = 0\n",
    "  const templates = []\n",
    "  let remainingStr = ''\n",
    "  while (true) {\n",
    "    const match = balanced('{{', '}}', remaining);\n",
    "    if (!match) {\n",
    "      remainingStr += remaining\n",
    "      break;\n",
    "    }\n",
    "    templates.push(match)\n",
    "    remainingStr += remaining.substring(0, match.start) + '{{template' + count + '}}'\n",
    "    remaining = remaining.substring(match.end + 2, remaining.length)\n",
    "    count++\n",
    "  }\n",
    "  //const templates = coalesceByPattern(wikiText, templateMatcher, matchTemplate);\n",
    "\n",
    "  //const remaining = templates.map((t, i) => '&template' + i + ';' + t.content.substr(t.raw.length)).join('')\n",
    "\n",
    "  const tags = [\"ref\", \"references\", \"syntaxhighlight\", \"code\", \"pre\", \"math\", \"gallery\", \"poem\"];\n",
    "  const tagRegex = new RegExp(\n",
    "    `<(${tags.join(\"|\")})\\\\b([^>]*)\\\\s*(\\\\/>)|<(${tags.join(\"|\")})\\\\b([^>]*)>([\\\\s\\\\S]*?)<\\\\/\\\\4>`,\n",
    "    \"gi\"\n",
    "  );\n",
    "  const pageTags = coalesceByPattern(remainingStr, tagRegex, matchTag)\n",
    "\n",
    "  //console.log(pageTags[0])\n",
    "  const linksFuncs = {}\n",
    "\n",
    "  const pageHtmlTags = pageTags.map((t, i) => {\n",
    "    if (t.raw.length === 0) {\n",
    "      return t.content\n",
    "    }\n",
    "    linksFuncs['tag' + i] = t.raw.replaceAll('<', '&lt;').replaceAll('>', '&gt;')\n",
    "    return '{{tag' + i + '}}' + t.content.substr(t.raw.length)\n",
    "  }).join('')\n",
    "\n",
    "  const links = []\n",
    "  remaining = pageHtmlTags\n",
    "  count = 0\n",
    "  while (true) {\n",
    "    const match = balanced('[[', ']]', remaining);\n",
    "    if (!match) break;\n",
    "    let newLink = matchWikiLinks((/(?:(\\w{2,12}):)?([^\\|\\]]+)(?:\\|([^\\]]+))?/gi).exec(match.body))\n",
    "    links.push(newLink)\n",
    "    remaining = remaining.substring(0, match.start) + '{{{link' + count + '}}}' + remaining.substring(match.end + 2, remaining.length)\n",
    "    if (newLink.type === 'file') {\n",
    "\n",
    "    } else {\n",
    "      linksFuncs['link' + count] = `<a href=\"/wiki/${newLink.target}\">${newLink.label}</a>`\n",
    "    }\n",
    "    count++\n",
    "  }\n",
    "\n",
    "  const linkRegex = /\\[(https?):\\/\\/(?:\\s([^\\]]+))?(?:[\\|\\s]([^\\]]+))?\\]/g;\n",
    "  const pageLinks = coalesceByPattern(remaining, linkRegex, matchWikiLinks)\n",
    "\n",
    "  const pageHtmlLinks = pageLinks.map((t, i) => {\n",
    "    if (t.raw.length === 0) {\n",
    "      return t.content\n",
    "    }\n",
    "    linksFuncs['link' + (count + i)] = `<a href=\"${t.target}\">${t.label}</a>`\n",
    "    return '{{{link' + (count + i) + '}}}' + t.content.substr(t.raw.length)\n",
    "  }).join('')\n",
    "\n",
    "  const tablePattern = /\\{\\|[\\s\\S]*?\\|\\}/g;\n",
    "\n",
    "  const tables = coalesceByPattern(pageHtmlLinks, tablePattern, matchTable)\n",
    "\n",
    "\n",
    "  const pageHtmlTables = tables.map((t, i) => {\n",
    "    return '{{table|' + i + '}}' + t.content.substr(t.raw.length)\n",
    "  }).join('')\n",
    "\n",
    "\n",
    "  const headingRegex = /(\\={1,6})\\s*(.*?)\\s*\\1\\s*/gm;\n",
    "\n",
    "  // finally removed everything that can interfere with sections headings equal signs\n",
    "  const sections = coalesceByPattern(pageHtmlTables, headingRegex, matchSection);\n",
    "\n",
    "  //console.log(sections)\n",
    "\n",
    "  return {\n",
    "    sections: sections.map(s => ({\n",
    "      depth: s.depth,\n",
    "      title: s.title,\n",
    "      content: md.render(formatWikitextSimple(Mustache.render(\n",
    "        s.content.substr(s.raw.length)\n",
    "\n",
    "          // Definition list ;term \\n :definition (ignore newlines, flatten first)\n",
    "          .replaceAll(/;[ \\t]*(.+?)[ \\t]*\\n?:[ \\t]*(.+?)(?=\\n|$)/g, (_, term, def) => {\n",
    "            return `<dl><dt>${term}</dt><dd>${def}</dd></dl>`;\n",
    "          })\n",
    "\n",
    "          // Blockquote: > lines (even in the middle of paragraphs)\n",
    "          .replaceAll(/(^|\\n)[ \\t]*>[ \\t]*(.*)/g, '$1<blockquote>$2</blockquote>')\n",
    "        , Object.assign({}, linksFuncs))))\n",
    "      //content: JSON.stringify()\n",
    "    })),\n",
    "  };\n",
    "}\n",
    "\n",
    "function formatWikitextSimple(wikiText) {\n",
    "  console.log(wikiText)\n",
    "  return wikiText\n",
    "    // Horizontal rule (----)\n",
    "    .replaceAll(/-{4,}/g, '<hr />')\n",
    "\n",
    "    // Bold + Italic: '''''text'''''\n",
    "    .replaceAll(/'''''(.*?)'''''/g, '<b><i>$1</i></b>')\n",
    "\n",
    "    // Bold: '''text'''\n",
    "    .replaceAll(/'''(.*?)'''/g, '<b>$1</b>')\n",
    "\n",
    "    // Italic: ''text''\n",
    "    .replaceAll(/''(.*?)''/g, '<i>$1</i>')\n",
    "\n",
    "    // Unordered list: one or more * with optional spacing\n",
    "    .replaceAll(/(^|\\n|[ \\t])[ \\t]*\\*+[ \\t]*([^\\*\\n]+)/g, (_, _2, item) => `<ul><li>${item}</li></ul>`)\n",
    "\n",
    "    // Ordered list: one or more # with optional spacing\n",
    "    .replaceAll(/(^|\\n|[ \\t])[ \\t]*\\#+[ \\t]*([^\\#\\n]+)/g, (_, _2, item) => `<ol><li>${item}</li></ol>`)\n",
    "    .replaceAll(/<\\/ul>\\s*<ul>/g, '')\n",
    "    .replaceAll(/<\\/ol>\\s*<ol>/g, '')\n",
    "\n",
    "  //.replaceAll('\\n\\n', '\\n<br />\\n')\n",
    "}\n",
    "\n",
    "function convertToParagraphs(wikitext) {\n",
    "  return wikitext\n",
    "    // Normalize line endings and trim\n",
    "    .replace(/\\r\\n?/g, '\\n')\n",
    "    .trim()\n",
    "\n",
    "    // Collapse multiple blank lines\n",
    "    .replace(/\\n{3,}/g, '\\n\\n')\n",
    "\n",
    "    // Convert double line breaks into paragraph breaks\n",
    "    .split(/\\n\\s*\\n/)\n",
    "    .map(block => `<p>${block.trim()}</p>`)\n",
    "    .join('\\n\\n');\n",
    "}\n",
    "function matchTable(match) {\n",
    "  const tableText = match[0];\n",
    "  const lines = tableText.split(/\\r?\\n/).map(line => line.trim());\n",
    "  const table = {\n",
    "    caption: null,\n",
    "    rows: [],\n",
    "  };\n",
    "\n",
    "  let currentRow = [];\n",
    "\n",
    "  for (let line of lines) {\n",
    "    if (line.startsWith('{|')) continue;\n",
    "    if (line.startsWith('|}')) {\n",
    "      if (currentRow.length) table.rows.push(currentRow);\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    if (line.startsWith('|+')) {\n",
    "      table.caption = line.substring(2).trim();\n",
    "    } else if (line.startsWith('|-')) {\n",
    "      if (currentRow.length) table.rows.push(currentRow);\n",
    "      currentRow = [];\n",
    "    } else if (line.startsWith('!')) {\n",
    "      // Header cells\n",
    "      const headers = line.substring(1).split(/!!/g).map(h => h.trim());\n",
    "      currentRow.push(...headers.map(text => ({ type: 'th', text })));\n",
    "    } else if (line.startsWith('|')) {\n",
    "      // Regular cells\n",
    "      const cells = line.substring(1).split(/\\|\\|/g).map(c => c.trim());\n",
    "      currentRow.push(...cells.map(text => ({ type: 'td', text })));\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return table\n",
    "}\n",
    "\n",
    "function matchWikiLinks(match) {\n",
    "  const langOrNs = match[1];\n",
    "  const target = match[2];\n",
    "  const label = match[3] || match[2];\n",
    "\n",
    "  let type = \"internal\";\n",
    "  if (langOrNs === \"Category\") type = \"category\";\n",
    "  if (langOrNs === \"File\") type = \"file\";\n",
    "  if (langOrNs === 'http') type = \"url\";\n",
    "  else if (langOrNs && langOrNs.length === 2) type = \"interwiki\";\n",
    "\n",
    "  return {\n",
    "    type,\n",
    "    lang: type === \"interwiki\" ? langOrNs : null,\n",
    "    target,\n",
    "    label,\n",
    "  };\n",
    "}\n",
    "\n",
    "function matchTag(match) {\n",
    "  const isSelfClosing = !!match[3];\n",
    "  const tagName = match[1] || match[4];\n",
    "  const attrs = match[2] || match[5] || \"\";\n",
    "  const content = isSelfClosing ? null : match[6];\n",
    "\n",
    "  return {\n",
    "    tag: tagName.toLowerCase(),\n",
    "    attributes: attrs.trim(),\n",
    "    inner: content,\n",
    "  };\n",
    "}\n",
    "\n",
    "function matchSection(match) {\n",
    "  const depth = match[1].length;\n",
    "  const title = match[2].trim();\n",
    "  return { depth, title };\n",
    "}\n",
    "\n",
    "function coalesceByPattern(text, regex, extractLabel = (match) => match[0]) {\n",
    "  const matches = [...text.matchAll(regex)];\n",
    "  const sections = [];\n",
    "\n",
    "  if (matches.length === 0) {\n",
    "    return [{ offset: 0, match: null, content: text, raw: '' }];\n",
    "  } else {\n",
    "    sections.push({\n",
    "      offset: 0,\n",
    "      match: null,\n",
    "      content: text.slice(0, matches[0].index),\n",
    "      raw: ''\n",
    "    })\n",
    "  }\n",
    "\n",
    "  for (let i = 0; i < matches.length; i++) {\n",
    "    const current = matches[i];\n",
    "    const next = matches[i + 1];\n",
    "\n",
    "    const startOffset = current.index;\n",
    "    const endOffset = next ? next.index : text.length;\n",
    "\n",
    "    sections.push(Object.assign({}, extractLabel(current), {\n",
    "      offset: startOffset,\n",
    "      match: current,\n",
    "      content: text.slice(startOffset, endOffset),\n",
    "      raw: current[0]\n",
    "    }));\n",
    "  }\n",
    "\n",
    "  return sections;\n",
    "}\n",
    "\n",
    "function matchTemplate([full, name, args]) {\n",
    "  const type = getTemplateType(name);\n",
    "  return {\n",
    "    type,\n",
    "    name,\n",
    "    args: args.trim(),\n",
    "  };\n",
    "}\n",
    "\n",
    "function getTemplateType(name) {\n",
    "  if (name.startsWith('#')) return 'parser_function';\n",
    "  if (name.toUpperCase() === name && name.length > 3) return 'magic_word';\n",
    "  if (/^infobox/i.test(name)) return 'infobox';\n",
    "  return 'template';\n",
    "}\n",
    "\n",
    "\n",
    "module.exports = preprocessDoc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2e70f",
   "metadata": {},
   "source": [
    "\n",
    "wikimedia mustache template?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024582f7",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "<h1>{{title}}</h1>\n",
    "<p><strong>Page ID:</strong> {{pageID}}</p>\n",
    "\n",
    "{{#categories.length}}\n",
    "<p><strong>Categories:</strong> {{#categories}}<span>{{.}}</span> {{/categories}}</p>\n",
    "{{/categories.length}}\n",
    "\n",
    "{{#sections}}\n",
    "<h{{depth}}>{{title}}</h{{depth}}>\n",
    "\n",
    "{{{content}}}\n",
    "\n",
    "{{#paragraphs}}\n",
    "<p>\n",
    "  {{#sentences}}\n",
    "  {{#text}}\n",
    "  {{{.}}}\n",
    "  {{/text}}\n",
    "  {{/sentences}}\n",
    "</p>\n",
    "{{/paragraphs}}\n",
    "\n",
    "{{#templates.length}}\n",
    "<h4>Templates</h4>\n",
    "<ul>\n",
    "  {{#templates}}\n",
    "  <li>{{{template}}}: {{{prop}}}</li>\n",
    "  {{/templates}}\n",
    "</ul>\n",
    "{{/templates.length}}\n",
    "\n",
    "{{#infoboxes}}\n",
    "<h4>Infoboxes</h4>\n",
    "{{{infoboxes}}}\n",
    "{{/infoboxes}}\n",
    "\n",
    "{{#references.length}}\n",
    "<h4>References</h4>\n",
    "<ul>\n",
    "  {{#references}}\n",
    "  <li>{{type}}: {{title}}</li>\n",
    "  {{/references}}\n",
    "</ul>\n",
    "{{/references.length}}\n",
    "\n",
    "{{/sections}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61187143",
   "metadata": {},
   "source": [
    "\n",
    "wikimedia service?\n",
    "\n",
    "ROUTE[] = /wiki/:article\n",
    "\n",
    "ROUTE[] = /wiki\n",
    "\n",
    "ROOT = true\n",
    "\n",
    "DEFAULT = true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ba501",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const readWikimedia = importer.import('list wikimedia articles')\n",
    "const levSearch = importer.import('search levenshtein distance')\n",
    "const levDist = importer.import('find the levenshtein distance')\n",
    "//const extractWikimedia = importer.import('wikimedia-page.html')\n",
    "const Mustache = require('mustache');\n",
    "\n",
    "async function searchWikimedia(req, res, next) {\n",
    "  let article = req.body['article'] || req.params['article'] || req.query['article'] || req.cookies['article']\n",
    "  let searchResults = await readWikimedia(article)\n",
    "\n",
    "  if (searchResults.length === 0) {\n",
    "    throw new Error('Page not found: ' + article)\n",
    "  }\n",
    "\n",
    "  console.log('sorting:', searchResults.length)\n",
    "  let sorted = levSearch(searchResults, { keys: ['title'] }, article)\n",
    "\n",
    "  console.log(sorted[0].title, levDist(sorted[0].title, article), sorted[1].title, levDist(sorted[1].title, article))\n",
    "  // check for multiple good matches and display a list\n",
    "  if ((sorted[0] && levDist(sorted[0].title, article) / article.length < 0.2\n",
    "    && sorted[1] && levDist(sorted[1].title, article) / article.length < 0.2)\n",
    "    // no great matches\n",
    "    || (levDist(sorted[0].title, article) / article.length > 0.5)\n",
    "  ) {\n",
    "    let template = importer.interpret('wikimedia mustache template').code\n",
    "    const content = Mustache.render(`\n",
    "<h1>Search results</h1>\n",
    "\n",
    "{{#sections}}\n",
    "<h2><a href=\"/wikimedia-page.html?offset={{offset}}&length={{length}}&search={{title}}\">{{title}}</a></h2>\n",
    "{{/sections}}\n",
    "`, {\n",
    "      sections: sorted\n",
    "    });\n",
    "    const html = Mustache.render(importer.interpret('wikiemedia clone index').code, {\n",
    "      content: content,\n",
    "      TIMESTAMP: Date.now()\n",
    "    });\n",
    "    return res.send(html)\n",
    "  }\n",
    "\n",
    "  //let content = extractWikimedia(sorted[0].offset, sorted[0].length, sorted[0].title)\n",
    "  return res.redirect('/wikimedia-page.html?offset=' + sorted[0].offset + '&length=' + sorted[0].length + '&search=' + sorted[0].title)\n",
    "}\n",
    "\n",
    "module.exports = searchWikimedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127906c",
   "metadata": {},
   "source": [
    "\n",
    "wikiemedia clone index?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f5368",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\" />\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "  <title>Shleppedia</title>\n",
    "  <link rel=\"stylesheet\" href=\"/wikimedia-style.css?t={{TIMESTAMP}}\">\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "  <header>\n",
    "    <h1>Shleppedia</h1>\n",
    "    <form id=\"search-box\" method=\"get\" action=\"/wiki\">\n",
    "      <input name=\"article\" type=\"text\" placeholder=\"Search articles...\">\n",
    "    </form>\n",
    "    <p>The slightly off-brand, slightly cooler encyclopedia clone</p>\n",
    "  </header>\n",
    "\n",
    "\n",
    "  <div id=\"main-content\">\n",
    "    <!-- Mustache-rendered content goes here -->\n",
    "    {{{ content }}}\n",
    "\n",
    "    <div class=\"infobox\">\n",
    "      <details open>\n",
    "        <summary>ðŸ§  Infobox Decoder</summary>\n",
    "        <div id=\"infobox-area\">\n",
    "          <!-- Dynamically rendered infobox properties here -->\n",
    "          <p>No infoboxes loaded yet.</p>\n",
    "        </div>\n",
    "      </details>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eade925",
   "metadata": {},
   "source": [
    "\n",
    "wikimedia-style?\n",
    "\n",
    "ROUTE = /wikimedia-style.css\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20e3bc",
   "metadata": {
    "vscode": {
     "languageId": "css"
    }
   },
   "outputs": [],
   "source": [
    "body {\n",
    "  margin: 0;\n",
    "  padding: 0;\n",
    "  font-family: system-ui, sans-serif;\n",
    "  background: #f9f9f9;\n",
    "  color: #333;\n",
    "}\n",
    "\n",
    "header {\n",
    "  background: #4b8bbe;\n",
    "  color: white;\n",
    "  padding: 1rem 2rem;\n",
    "  display: flex;\n",
    "  align-items: center;\n",
    "  justify-content: space-between;\n",
    "  flex-wrap: wrap;\n",
    "  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
    "}\n",
    "\n",
    "header h1 {\n",
    "  font-size: 1.8rem;\n",
    "  margin: 0;\n",
    "  flex: 0;\n",
    "}\n",
    "\n",
    "#search-box {\n",
    "  flex: 2;\n",
    "  max-width: 400px;\n",
    "  display: flex;\n",
    "  justify-content: flex-end;\n",
    "}\n",
    "\n",
    "#search-box input {\n",
    "  width: 100%;\n",
    "  padding: 0.5rem 0.75rem;\n",
    "  font-size: 1rem;\n",
    "  border: 1px solid #ccc;\n",
    "  border-radius: 4px;\n",
    "  outline: none;\n",
    "  transition: border-color 0.3s;\n",
    "  background: white;\n",
    "}\n",
    "\n",
    "#search-box input:focus {\n",
    "  border-color: #2e6fa3;\n",
    "}\n",
    "\n",
    "#main-content {\n",
    "  width: 100%;\n",
    "  max-width: 1200px;\n",
    "  margin: 2rem auto;\n",
    "  padding: 2rem;\n",
    "  background: white;\n",
    "  border-radius: 8px;\n",
    "  box-shadow: 0 0 8px rgba(0, 0, 0, 0.05);\n",
    "}\n",
    "\n",
    ".infobox {\n",
    "  margin-top: 2rem;\n",
    "  padding: 1rem;\n",
    "  border-left: 4px solid #4b8bbe;\n",
    "  background: #eef6ff;\n",
    "}\n",
    "\n",
    "details summary {\n",
    "  cursor: pointer;\n",
    "  font-weight: bold;\n",
    "}\n",
    "\n",
    "a {\n",
    "  color: #2970b8;\n",
    "  text-decoration: none;\n",
    "}\n",
    "\n",
    "a:hover {\n",
    "  text-decoration: underline;\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
