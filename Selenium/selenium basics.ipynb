{
  "cells": [
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "# Selenium Basics in Docker\n\n",
     "This notebook walks you through:\n",
     "- Setting up Selenium inside Docker\n",
     "- Mounting a volume to run local scripts\n",
     "- Collecting information from web pages\n",
     "- Scraping data from real websites\n",
     "- Saving scraped data to your host machine"
    ]
   },
   {
    "cell_type": "code",
    "metadata": {},
    "execution_count": null,
    "outputs": [],
    "source": [
     "# Dockerfile for Selenium + Python + Chrome\n",
     "FROM selenium/standalone-chrome-debug\n\n",
     "USER root\n",
     "RUN apt-get update && apt-get install -y python3-pip\n",
     "RUN pip3 install selenium pandas beautifulsoup4\n\n",
     "WORKDIR /home/seluser/scripts\n",
     "VOLUME /home/seluser/scripts\n",
     "CMD [\"tail\", \"-f\", \"/dev/null\"]"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Build and run the container with volume mounted:\n",
     "Assumes you're in the folder containing your scraping scripts."
    ]
   },
   {
    "cell_type": "code",
    "metadata": {},
    "execution_count": null,
    "outputs": [],
    "source": [
     "docker build -t selenium-lab .\n",
     "docker run -it --rm \\\n",
     "  -v $(pwd)/scripts:/home/seluser/scripts \\\n",
     "  -p 4444:4444 -p 5900:5900 selenium-lab"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Python Script: Launch Chrome and navigate to a page"
    ]
   },
   {
    "cell_type": "code",
    "metadata": {},
    "execution_count": null,
    "outputs": [],
    "source": [
     "# file: open_google.py\n",
     "from selenium import webdriver\n",
     "from selenium.webdriver.common.by import By\n\n",
     "options = webdriver.ChromeOptions()\n",
     "options.add_argument('--no-sandbox')\n",
     "options.add_argument('--disable-dev-shm-usage')\n",
     "driver = webdriver.Chrome(options=options)\n\n",
     "driver.get('https://www.google.com')\n",
     "print(\"Title:\", driver.title)\n",
     "driver.quit()"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### Example: Scrape Python job listings from RemoteOK"
    ]
   },
   {
    "cell_type": "code",
    "metadata": {},
    "execution_count": null,
    "outputs": [],
    "source": [
     "# file: scrape_jobs.py\n",
     "from selenium import webdriver\n",
     "from selenium.webdriver.common.by import By\n",
     "import pandas as pd\n\n",
     "driver = webdriver.Chrome()\n",
     "driver.get('https://remoteok.com/remote-dev+python-jobs')\n\n",
     "jobs = driver.find_elements(By.CSS_SELECTOR, 'tr.job')\n",
     "data = []\n",
     "for job in jobs:\n",
     "    title = job.find_element(By.CSS_SELECTOR, 'td.position h2').text\n",
     "    company = job.find_element(By.CSS_SELECTOR, 'td.company h3').text\n",
     "    data.append({\"title\": title, \"company\": company})\n\n",
     "driver.quit()\n",
     "df = pd.DataFrame(data)\n",
     "df.to_csv('python_jobs.csv', index=False)\n",
     "print(df.head())"
    ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "### More ideas to try:\n",
     "- Log in to a test website and collect dashboard data\n",
     "- Monitor prices on a product page\n",
     "- Extract all links from a webpage\n",
     "- Capture screenshots during browsing sessions"
    ]
   },
   {
    "cell_type": "code",
    "metadata": {},
    "execution_count": null,
    "outputs": [],
    "source": [
     "# Screenshot example\n",
     "driver = webdriver.Chrome()\n",
     "driver.get('https://example.com')\n",
     "driver.save_screenshot('example.png')\n",
     "driver.quit()"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "name": "python"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 2
 }
 