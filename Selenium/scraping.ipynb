{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "# Scraping Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LLM Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Article Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### the code\n",
    "\n",
    "extract llm article?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const getClient = importer.import('selenium client')\n",
    "//const llama = importer.import('llm code')\n",
    "const selectDom = importer.import('selenium select')\n",
    "\n",
    "// TODO: help me extract this article from html, only return the article in plain text and remove the html:\n",
    "\n",
    "\n",
    "async function extractArticle(driver, startPage, retry) {\n",
    "  //let llmCode = await llama\n",
    "\n",
    "  if (!driver)\n",
    "    driver = await getClient()\n",
    "\n",
    "  if (!startPage) {\n",
    "    return\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    console.log('loading page ', startPage)\n",
    "\n",
    "    await driver.get(startPage)\n",
    "\n",
    "    await new Promise(resolve => setTimeout(resolve, 1500))\n",
    "\n",
    "    let bodyElements = await selectDom(driver, ['//body//*[text() and not(self::script|self::style|self::form) and not(ancestor::aside|ancestor::nav|ancestor::form|ancestor::header)]'])\n",
    "    let bodyText = []\n",
    "\n",
    "    for (let i = 0; i < bodyElements.length; i++) {\n",
    "      try {\n",
    "        let text = await bodyElements[i].getText()\n",
    "        bodyText.push(text)\n",
    "      } catch (e) {\n",
    "        if (e.message.includes('stale element reference')) {\n",
    "          continue\n",
    "        } else {\n",
    "          throw e\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    return bodyText\n",
    "      .map(t => Array.isArray(t) ? t.join('\\n').trim() : t.trim())\n",
    "      .filter(t => t.length)\n",
    "      .join('\\n')\n",
    "    /*\n",
    "        let q1 = 'Extract the text content from this HTML page without forming any new HTML code:\\n'\n",
    "          + bodyElements.join('\\n') + '\\nReturn plain text extracted from the page and nothing else.'\n",
    "    \n",
    "        console.log('User: ' + q1)\n",
    "        let a1 = await llmCode(q1)\n",
    "        console.log('AI: ' + a1)\n",
    "    \n",
    "        let code = a1.matchAll(/```(markdown)*\\n[\\s\\S]*?\\n```/gi)\n",
    "    \n",
    "        // extract code blocks from response\n",
    "        let codeBlocks = ''\n",
    "        for(let match of code) {\n",
    "          codeBlocks += match[0].replace(/^```(markdown)*\\n|\\n```$/gi, '') + '\\n'\n",
    "        }\n",
    "        if(!codeBlocks) {\n",
    "          console.log('Error, couldn\\'t find code in:' + a1)\n",
    "          return\n",
    "        }\n",
    "    \n",
    "        return codeBlocks.join('\\n')\n",
    "    */\n",
    "\n",
    "  } catch (up) {\n",
    "    if (!up.message.includes('page crash')) {\n",
    "      driver.quit()\n",
    "\n",
    "      throw up\n",
    "    } else if(!retry) {\n",
    "      return await extractArticle(driver, startPage, true)\n",
    "    } else {\n",
    "      throw up\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "module.exports = extractArticle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "test article extract?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "const extractArticle = importer.import('extract llm article')\n",
    "const getClient = importer.import('selenium client')\n",
    "\n",
    "async function testExtractor(startPage) {\n",
    "  if(!startPage) {\n",
    "    startPage = 'https://tsakraklides.com/2025/02/05/in-the-age-of-infinite-consumer-choice-the-only-choice-is-collapse/'\n",
    "  }\n",
    "\n",
    "  driver = await getClient()\n",
    "\n",
    "  let result = await extractArticle(driver, startPage)\n",
    "\n",
    "  driver.quit()\n",
    "\n",
    "  return result\n",
    "}\n",
    "\n",
    "\n",
    "module.exports = testExtractor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Summarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### the code\n",
    "\n",
    "summarize llm article?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "const llama = importer.import('create llm session')\n",
    "\n",
    "// TODO: prompt llm, in one sentence summarize this article. in a whole paragraph summarize this article.\n",
    "\n",
    "async function summerizeArticle(article, funny) {\n",
    "  let {llmPrompt} = await llama\n",
    "\n",
    "  if(!funny) {\n",
    "    funny = ''\n",
    "  }\n",
    "\n",
    "  let q1 = 'Summerize this article in a single paragraph ' + funny + ':\\n' + article.substr(0, 4096) + '\\nOnly return the summary and nothing else, no explanations.'\n",
    "  console.log('User: ' + q1)\n",
    "  let a1 = await llmPrompt(q1)\n",
    "  console.log('AI: ' + a1)\n",
    "\n",
    "\n",
    "  let q2 = 'Summerize this article in a single sentence ' + funny + ':\\n' + article.substr(0, 4096) + '\\nOnly return the summary and nothing else, no explanations.'\n",
    "  console.log('User: ' + q2)\n",
    "  let a2 = await llmPrompt(q2)\n",
    "  console.log('AI: ' + a2)\n",
    "\n",
    "  return [a1, a2]\n",
    "}\n",
    "\n",
    "\n",
    "module.exports = summerizeArticle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "test article summarizer?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const extractArticle = importer.import('extract llm article')\n",
    "const getClient = importer.import('selenium client')\n",
    "const summerizeArticle = importer.import('summarize llm article')\n",
    "\n",
    "async function testExtractor(startPage) {\n",
    "  if (!startPage) {\n",
    "    startPage = 'https://tsakraklides.com/2025/02/05/in-the-age-of-infinite-consumer-choice-the-only-choice-is-collapse/'\n",
    "  }\n",
    "\n",
    "  driver = await getClient()\n",
    "\n",
    "  try {\n",
    "\n",
    "    let result = await extractArticle(driver, startPage)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    let summary = await summerizeArticle(result)\n",
    "\n",
    "    return summary\n",
    "  } catch (e) {\n",
    "    driver.quit()\n",
    "\n",
    "    throw e\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "module.exports = testExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Summarize All\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### the code\n",
    "\n",
    "summarize all articles?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const getClient = importer.import('selenium client')\n",
    "const extractArticle = importer.import('extract llm article')\n",
    "const summerizeArticle = importer.import('summarize llm article')\n",
    "const {\n",
    "  defaultCollector, persistSummaries\n",
    "} = importer.import('default link collector')\n",
    "\n",
    "// select link scraping tool\n",
    "function selectScaper(selector, startPage) {\n",
    "  if(!selector && startPage.includes('reddit.com')) {\n",
    "    selector = importer.import('reddit month of links')\n",
    "  } else if(!selector) {\n",
    "    selector = defaultCollector\n",
    "  } else if(typeof selector == 'string') {\n",
    "    selector = defaultCollector.bind(null, startPage, selector)\n",
    "  }\n",
    "\n",
    "  return selector\n",
    "}\n",
    "\n",
    "// extract persist, extract persist\n",
    "async function summerizeAll(links, selector, startPage, funny) {\n",
    "\n",
    "  if(!startPage && !links) {\n",
    "    console.error('No start page or links to summerize.')\n",
    "    return\n",
    "  }\n",
    "\n",
    "  let selectorFunction = selectScaper(selector, startPage)\n",
    "\n",
    "  let driver = await getClient()\n",
    "\n",
    "  let summaries = persistSummaries(funny)\n",
    "\n",
    "  try {\n",
    "    if(!links && startPage) {\n",
    "      links = await selectorFunction(driver, startPage)\n",
    "    }\n",
    "\n",
    "    console.log(links)\n",
    "\n",
    "    for (let i = 0; i < links.length; i++) {\n",
    "      if(typeof summaries[links[i].link] != 'undefined')\n",
    "        continue // already loaded\n",
    "\n",
    "      let article = await extractArticle(driver, links[i].link)\n",
    "\n",
    "      let summary = await summerizeArticle(article, funny)\n",
    "      \n",
    "      summaries[links[i].link] = summary\n",
    "      persistSummaries(funny, summaries)\n",
    "    }\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return summaries\n",
    "  } catch (e) {\n",
    "    //driver.quit()\n",
    "    throw e\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = summerizeAll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Convert Summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### the code\n",
    "\n",
    "convert summaries?\n",
    "\n",
    "TODO: rewrite this to be more useful\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const path = require('path')\n",
    "const { safeurl } = importer.import('domain cache tools')\n",
    "const { getNearestSunday } = importer.import('default link collector')\n",
    "const summerizeArticle = importer.import('summarize all articles')\n",
    "const llama = importer.import('create llm session')\n",
    "\n",
    "const PROJECT_PATH = path.join(__dirname, '..', 'Resources', 'Projects', 'reasonings')\n",
    "\n",
    "const CONVERSION_PROMPTS = [\n",
    "  'summary',\n",
    "  'pretend you\\'re living in a star wars themed universe and reverse sentence structure like Yoda',\n",
    "  'pretend you\\'re a super intelligent alien species and write a metaphor for how they could be teasing us',\n",
    "  'break the news to me as gently as possible, mommy me a little and tell me it\\'s going to be okay',\n",
    "  'Rewrite this news story as if it were a stand-up comedy routine, complete with witty punchlines and audience reactions',  \n",
    "  'Make this breaking news sound like a script for a sitcom, with awkward misunderstandings, dramatic pauses, and a laugh track',  \n",
    "  'Turn this serious news article into a rhyming Dr. Seuss-style poem, making it lighthearted but still informative',  \n",
    "  'Retell this news story from the perspective of a sarcastic but lovable talking animal who’s just trying to make sense of the human world',  \n",
    "  'Rewrite this news article as if it were an absurd conspiracy theory from a tin-foil-hat-wearing enthusiast',  \n",
    "  'Make this news sound like an over-the-top tabloid headline, with wild exaggerations and celebrity name-drops',  \n",
    "  'Rephrase this bad news as if you were a kindergarten teacher gently explaining it to a room full of toddlers',  \n",
    "  'Write this difficult news as if it were a whimsical fairy tale where things work out in the end (or at least have a hopeful moral)',  \n",
    "  'Turn this stressful news into a motivational speech, making it sound like an inspiring challenge rather than a disaster',  \n",
    "  'Rewrite this news as if a wise old grandma was breaking it to you over a warm cup of tea and cookies',  \n",
    "  'Make this bad news sound like a quirky horoscope, full of mystical optimism and cosmic reassurance',  \n",
    "  'Transform this news into an uplifting bedtime story where even the roughest parts have a silver lining'\n",
    "]\n",
    "\n",
    "async function alternativeSummary(summary, funny) {\n",
    "  let { llmPrompt } = await llama\n",
    "\n",
    "  let q1 = 'Convert this article summary, ' + funny + ':\\n' + summary[0] + '\\nOnly return the summary and nothing else, no explanations.'\n",
    "  console.log('User: ' + q1)\n",
    "  let a1 = await llmPrompt(q1)\n",
    "  console.log('AI: ' + a1)\n",
    "\n",
    "\n",
    "  let q2 = 'Convert this article description, ' + funny + ':\\n' + summary[1] + '\\nOnly return the single sentence and nothing else, no explanations.'\n",
    "  console.log('User: ' + q2)\n",
    "  let a2 = await llmPrompt(q2)\n",
    "  console.log('AI: ' + a2)\n",
    "\n",
    "  return [a1, a2]\n",
    "}\n",
    "\n",
    "async function alternativeArticles(startPage, random) {\n",
    "\n",
    "  // TODO: get base summary, if it doesn't exist generate it\n",
    "  const CONVERSION_FILES = CONVERSION_PROMPTS.map(funny =>\n",
    "    path.join(PROJECT_PATH, safeurl(getNearestSunday()) + '-' + safeurl(funny) + '.json'))\n",
    "\n",
    "\n",
    "  // TODO: get a list of all other summary conversions\n",
    "  const allSummaries = []\n",
    "  for (let i = 0; i < CONVERSION_FILES.length; i++) {\n",
    "    if (fs.existsSync(CONVERSION_FILES[i]))\n",
    "      allSummaries[i] = JSON.parse(fs.readFileSync(CONVERSION_FILES[i]))\n",
    "    else\n",
    "      allSummaries[i] = {}\n",
    "  }\n",
    "\n",
    "  if (Object.values(allSummaries[0]).length == 0) {\n",
    "    allSummaries[0] = await summerizeArticle(startPage)\n",
    "  }\n",
    "\n",
    "  // TODO: convert the base summaries to funny conversions and save\n",
    "  let links = Object.keys(allSummaries[0])\n",
    "  if(random) {\n",
    "    random = Math.round(Math.random() * (CONVERSION_PROMPTS.length - 1)) + 1\n",
    "  }\n",
    "  for (let i = 0; i < links.length; i++) {\n",
    "    for (let j = random ? random : 1; j < CONVERSION_PROMPTS.length; j++) {\n",
    "\n",
    "      if(typeof allSummaries[j][links[i]] != 'undefined') {\n",
    "        continue\n",
    "      }\n",
    "\n",
    "      // TODO: persist\n",
    "      allSummaries[j][links[i]] = await alternativeSummary(allSummaries[0][links[i]], CONVERSION_PROMPTS[j])\n",
    "      fs.writeFileSync(CONVERSION_FILES[j], JSON.stringify(allSummaries[j], null, 4))\n",
    "      \n",
    "      if(random) {\n",
    "        break\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return allSummaries\n",
    "}\n",
    "\n",
    "\n",
    "module.exports = {\n",
    "  alternativeArticles,\n",
    "  alternativeSummary,\n",
    "  CONVERSION_PROMPTS,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scaper Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Default Collector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### the code\n",
    "\n",
    "default link collector?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "const fs = require('fs')\n",
    "const path = require('path')\n",
    "const {safeurl} = importer.import('domain cache tools')\n",
    "\n",
    "const PROJECT_PATH = path.join(__dirname, '..', 'Resources', 'Projects', 'reasonings')\n",
    "\n",
    "function getNearestSunday(date = new Date()) {\n",
    "  const day = date.getDay();\n",
    "  const diff = date.getDate() - day + (day === 0 ? -7 : 0); // adjust when it is Sunday\n",
    "  const result = new Date(date.setDate(diff));\n",
    "  const customString = `${result.getMonth() + 1}/${result.getDate()}/${result.getFullYear()}`; \n",
    "  return customString\n",
    "}\n",
    "\n",
    "async function defaultCollector(driver, startPage, selector = '//a[@href]/@href') {\n",
    "  const selectDom = importer.import('selenium select')\n",
    "  const getClient = importer.import('selenium client')\n",
    "  if(!driver)\n",
    "    driver = getClient()\n",
    "\n",
    "  try {\n",
    "    await driver.get(startPage)\n",
    "    await new Promise(resolve => setTimeout(resolve, 1000))\n",
    "    let links = await selectDom(driver, selector)\n",
    "    return links.map(l => ({link: l})) // to match reddit post lister\n",
    "  } catch (e) {\n",
    "    driver.quit()\n",
    "    throw e\n",
    "  }\n",
    "}\n",
    "\n",
    "// record previously generated summaries so script will eventually complete\n",
    "function persistSummaries(funny, summaries) {\n",
    "  if(!funny) {\n",
    "    funny = 'summary'\n",
    "  }\n",
    "  let weeklySummary = path.join(PROJECT_PATH, safeurl(getNearestSunday()) + '-' + safeurl(funny) + '.json')\n",
    "  if(!summaries && fs.existsSync(weeklySummary)) {\n",
    "    return JSON.parse(fs.readFileSync(weeklySummary))\n",
    "  } else if (!summaries) {\n",
    "    return {}\n",
    "  } else {\n",
    "    fs.writeFileSync(weeklySummary, JSON.stringify(summaries, null, 4))\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  defaultCollector,\n",
    "  getNearestSunday,\n",
    "  persistSummaries,\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
