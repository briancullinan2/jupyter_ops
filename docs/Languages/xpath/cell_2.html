<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>Cell 2</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    html {
      padding: 0;
      margin: 0;
    }

    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
      padding: 10px;
    }

    body {
      padding: 0 0 0 200px;
      margin: 0;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <h3><a href="../xpath/index.html">xpath</a></h3>
    <a href="./cell_0.html">Cell 0</a>
<br /><br />
<a href="./cell_1.html">Cell 1</a>
<br /><br />
<a href="./cell_2.html">Cell 2</a>
<br /><br />
<a href="./cell_3.html">Cell 3</a>
<br /><br />
<a href="./cell_4.html">Cell 4</a>
<br /><br />
<a href="./cell_5.html">Cell 5</a>
<br /><br />
<a href="./cell_6.html">Cell 6</a>
<br /><br />

  </nav>
  <header>
    <a href="../xpath/index.html">xpath</a> | <a href="./cell_1.html">Cell 1</a> | <a href="./cell_3.html">Cell 3</a> | <a href="../../search.html">Search</a>
  </header>

  <p>This code defines a lexer for XPath expressions using the <code>ply</code> module, specifying tokens and their corresponding regular expression patterns to recognize XPath operators, separators, and literal values. The lexer can be used as a foundation for building a parser that constructs an abstract syntax tree (AST) for further processing, making it a crucial component for XPath expression analysis.</p>
<h1>Cell 2</h1>



<pre class="python"><code>"""XPath lexing rules.

To understand how this module works, it is valuable to have a strong
understanding of the `ply &lt;http://www.dabeaz.com/ply/&gt;` module.
"""

from __future__ import unicode_literals

operator_names = {
    'or': 'OR_OP',
    'and': 'AND_OP',
    'div': 'DIV_OP',
    'mod': 'MOD_OP',
}

tokens = [
        'PATH_SEP',
        'ABBREV_PATH_SEP',
        'ABBREV_STEP_SELF',
        'ABBREV_STEP_PARENT',
        'AXIS_SEP',
        'ABBREV_AXIS_AT',
        'OPEN_PAREN',
        'CLOSE_PAREN',
        'OPEN_BRACKET',
        'CLOSE_BRACKET',
        'UNION_OP',
        'EQUAL_OP',
        'REL_OP',
        'PLUS_OP',
        'MINUS_OP',
        'MULT_OP',
        'STAR_OP',
        'COMMA',
        'LITERAL',
        'FLOAT',
        'INTEGER',
        'NCNAME',
        'NODETYPE',
        'FUNCNAME',
        'AXISNAME',
        'COLON',
        'DOLLAR',
    ] + list(operator_names.values())

t_PATH_SEP = r'/'
t_ABBREV_PATH_SEP = r'//'
t_ABBREV_STEP_SELF = r'\.'
t_ABBREV_STEP_PARENT = r'\.\.'
t_AXIS_SEP = r'::'
t_ABBREV_AXIS_AT = r'@'
t_OPEN_PAREN = r'\('
t_CLOSE_PAREN = r'\)'
t_OPEN_BRACKET = r'\['
t_CLOSE_BRACKET = r'\]'
t_UNION_OP = r'\|'
t_EQUAL_OP = r'!?='
t_REL_OP = r'[&lt;&gt;]=?'
t_PLUS_OP = r'\+'
t_MINUS_OP = r'-'
t_COMMA = r','
t_COLON = r':'
t_DOLLAR = r'\
</body>

</html>
t_STAR_OP = r'\*'

t_ignore = ' \t\r\n'

# NOTE: some versions of python cannot compile regular expressions that
# contain unicode characters above U+FFFF, which are allowable in NCNames.
# These characters can be used in Python 2.6.4, but can NOT be used in 2.6.2
# (status in 2.6.3 is unknown).  The code below accounts for that and excludes
# the higher character range if Python can't handle it.

# Monster regex derived from:
#  http://www.w3.org/TR/REC-xml/#NT-NameStartChar
#  http://www.w3.org/TR/REC-xml/#NT-NameChar
# EXCEPT:
# Technically those productions allow ':'. NCName, on the other hand:
#  http://www.w3.org/TR/REC-xml-names/#NT-NCName
# explicitly excludes those names that have ':'. We implement this by
# simply removing ':' from our regexes.

# NameStartChar regex without characters about U+FFFF
NameStartChar = r'[A-Z]|_|[a-z]|\xc0-\xd6]|[\xd8-\xf6]|[\xf8-\u02ff]|' + \
    r'[\u0370-\u037d]|[\u037f-\u1fff]|[\u200c-\u200d]|[\u2070-\u218f]|' + \
    r'[\u2c00-\u2fef]|[\u3001-\uD7FF]|[\uF900-\uFDCF]|[\uFDF0-\uFFFD]'
# complete NameStartChar regex
Full_NameStartChar = r'(' + NameStartChar + r'|[\U00010000-\U000EFFFF]' + r')'
# additional characters allowed in NCNames after the first character
NameChar_extras = r'[-.0-9\xb7\u0300-\u036f\u203f-\u2040]'

try:
    import re
    # test whether or not re can compile unicode characters above U+FFFF
    re.compile(r'[\U00010000-\U00010001]')
    # if that worked, then use the full ncname regex
    NameStartChar = Full_NameStartChar
except:
    # if compilation failed, leave NameStartChar regex as is, which does not
    # include the unicode character ranges above U+FFFF
    pass

NCNAME_REGEX = r'(' + NameStartChar + r')(' + \
                      NameStartChar + r'|' + NameChar_extras + r')*'

NODE_TYPES = set(['comment', 'text', 'processing-instruction', 'node'])

t_NCNAME = NCNAME_REGEX

def t_LITERAL(t):
    r""""[^"]*"|'[^']*'"""
    t.value = t.value[1:-1]
    return t

def t_FLOAT(t):
    r'\d+\.\d*|\.\d+'
    t.value = float(t.value)
    return t

def t_INTEGER(t):
    r'\d+'
    t.value = int(t.value)
    return t

def t_error(t):
    raise TypeError("Unknown text '%s'" % (t.value,))</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>

<script>hljs.highlightAll();</script>

<p><strong>Overview of the Code</strong></p>
<p>This code is a lexer definition for XPath using the <code>ply</code> module. It defines a set of tokens and their corresponding regular expression patterns.</p>
<p><strong>Structure</strong></p>
<p>The code consists of the following sections:</p>
<ol>
<li><strong>Import statements</strong>: The code imports the <code>unicode_literals</code> module from <code>__future__</code> to ensure that strings are treated as Unicode literals.</li>
<li><strong>Operator names</strong>: A dictionary <code>operator_names</code> is defined to map XPath operator names to their corresponding token names.</li>
<li><strong>Token definitions</strong>: A list <code>tokens</code> is defined to specify the set of tokens that will be recognized by the lexer. This list includes token names and their corresponding regular expression patterns.</li>
<li><strong>Regular expression patterns</strong>: Each token in the <code>tokens</code> list is assigned a regular expression pattern using the <code>t_</code> syntax.</li>
<li><strong>Ignored characters</strong>: A regular expression pattern <code>t_ignore</code> is defined to specify characters that will be ignored by the lexer.</li>
<li><strong>NCName characters</strong>: A section of code is included to handle characters that are not compatible with all versions of Python.</li>
</ol>
<p><strong>Key Concepts</strong></p>
<ul>
<li><strong>Tokens</strong>: A token is a basic unit of the language that the lexer will recognize. In this code, tokens include XPath operators, separators, and literal values.</li>
<li><strong>Regular expressions</strong>: Regular expressions are used to define the patterns for each token.</li>
<li><strong>Ply</strong>: The <code>ply</code> module is a Python implementation of the lex and yacc tools, which are used to build parsers and lexers.</li>
</ul>
<p><strong>Example Use Case</strong></p>
<p>This code would be used as a foundation for building a parser that can understand XPath expressions. The parser would use the definitions in this code to recognize the tokens in the XPath expression and construct an abstract syntax tree (AST) that can be used for further processing.</p>

</body>

</html>