<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>Like all facebook posts</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
    }

    body {
      padding-left: 200px;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <a href="../facebook_data/index.html">facebook data</a>
    <br /><br />
    <a href="./Log_in_to_facebook.html">Log in to facebook</a>
<br /><br />
<a href="./Scrape_facebook_profile.html">Scrape facebook profile</a>
<br /><br />
<a href="./Like_all_facebook_posts.html">Like all facebook posts</a>
<br /><br />
<a href="./Scrape_facebook_event.html">Scrape facebook event</a>
<br /><br />
<a href="./Scrape_facebook_events.html">Scrape facebook events</a>
<br /><br />
<a href="./cell_5.html">Cell 5</a>
<br /><br />
<a href="./Scrape_facebook_friends.html">Scrape facebook friends</a>
<br /><br />
<a href="./Automatically_diff_facebook_friends.html">Automatically diff facebook friends</a>
<br /><br />
<a href="./cell_8.html">Cell 8</a>
<br /><br />
<a href="./Unfollow_everyone_on_facebook.html">Unfollow everyone on facebook</a>
<br /><br />
<a href="./cell_10.html">Cell 10</a>
<br /><br />
<a href="./cell_11.html">Cell 11</a>
<br /><br />

  </nav>
  <header>
    <a href="../facebook_data/index.html">facebook data</a> ${PREV} ${NEXT}
  </header>

  <p>This code automates the process of scraping Facebook posts, fetching their URLs and extracting details like descriptions and participant profiles using Puppeteer.</p>


<pre class="javascript"><code>var glob = require('glob');
var importer = require('../Core');
var fs = require('fs');

var PROFILE_PATH = process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE;
var project = PROFILE_PATH + '/Conversations';

function listFacebookPosts(profile, posts = []) {
    return client
        .then(() =&gt; getAllUntil(
            '//body',
            '//*[contains(@class, "timestampContent")]/parent::*/parent::*/@href',
            posts,
            (a, b) =&gt; a === b,
            (i) =&gt; i &lt; 20
        ))
        // transform add facebook url
        .then(r =&gt; {
        return r.map(l =&gt; l.indexOf('facebook.com') === -1
            ? ('https://www.facebook.com' + l)
            : l)
    })
        .catch(e =&gt; console.log(e))
};

function scrapeFacebookPost(post) {
    console.log(post);
    return client
        .getUrl().then(url =&gt; url.indexOf(post) == -1
            ? client.url(post)
            : client)
        .pause(post.indexOf('video') &gt; -1 ? 4000 : 2000)
        .then(() =&gt; getAllXPath([
            '//body[not(.//*[contains(@class, "fbPhotoSnowliftPopup")])]|//body[.//*[contains(@class, "fbPhotoSnowliftPopup")]]//*[contains(@class, "fbPhotoSnowliftPopup")]',
            {
                posts: [
                    './/*[contains(@class, "userContentWrapper")]|.//*[contains(@class, "fbUserPost")]|.//*[contains(@class, "fbUserStory")]',
                    {
                        description:
                            './/following-sibling::div//*[contains(@class, "fbPhotosPhotoCaption")]//text()|.//*[contains(@class, "userContent")]//text()|.//h5//text()|.//a[contains(@class, "profileLink")]//text()',
                        participants: [
                            './/a[contains(@class, "profileLink")]/@href|.//a[contains(@href, "facebook") and .//img]/@href',
                            './following-sibling::div//a/@href',
                            './/*[contains(@class, "commentable_item")]//a[contains(@class, "UFICommentActorName")]/@href'
                        ],
                        comments: [
                            './/h6[contains(., "Comments")]//following-sibling::div/div/div[contains(@class, "UFIComment")]',
                            {
                                time:
                                    './/*[contains(@class, "uiLinkSubtle")]//text()',
                                content:
                                    './/*[contains(@class, "UFICommentBody")]//text()',
                                from:
                                    './/a[contains(@class, "UFICommentActorName")]/text()|.//a[contains(@class, "UFICommentActorName")]/@href'
                            }
                        ]
                    }
                ]
            }
        ]))
        .then(r =&gt; r[0].posts.map(p =&gt; {
            return Object.assign(p, {
                post: post,
                description: typeof p.description === 'string' ? p.description : p.description.join(' '),
                participants: p.participants.filter(i =&gt; i
                        .indexOf('photo') === -1
                    &amp;&amp; i !== '#'
                    &amp;&amp; i.indexOf('ufi/reaction') === -1),
                photos: p.participants.filter(i =&gt; i
                        .indexOf('photo') !== -1
                    &amp;&amp; i !== '#'
                    &amp;&amp; i.indexOf('ajax/sharer') === -1),
                comments: p.comments.map(c =&gt; Object.assign(c, {
                    time: typeof c.time === 'string' ? c.time : c.time.join(' '),
                    content: typeof c.content === 'string' ? c.content : c.content.join(' '),
                    from: typeof c.from === 'string' ? c.from : c.from.join(' ')
                }))
            });
        }))
        .catch(e =&gt; console.log(e))
};

function likeFacebookPost(post) {
    return client
        .getUrl().then(url =&gt; url.indexOf(post) === -1
            ? client.url(post)
            : client)
        .pause(post.indexOf('video') &gt; -1 ? 4000 : 2000)
        .elements(
            '//body[not(.//*[contains(@class, "fbPhotoSnowliftPopup")])]//a[contains(., "Like")][contains(@class, "UFILikeLink")][not(contains(@class, "UFILinkBright"))]|//body[.//*[contains(@class, "fbPhotoSnowliftPopup")]]//*[contains(@class, "fbPhotoSnowliftPopup")]//a[contains(., "Like")][contains(@class, "UFILikeLink")][not(contains(@class, "UFILinkBright"))]')
        .then(els =&gt; {
            return importer.runAllPromises(els.value.slice(0, 4)
                .map(el =&gt; (resolve) =&gt; client.elementIdClick(el.ELEMENT)
                    .pause(1500)
                    .catch(e =&gt; resolve())
                    .then(() =&gt; resolve())))
        })
        .catch(e =&gt; console.log(e));
}

var posts;
function likeAllPosts(profile, like = null) {
    var profileId = profile.replace(/^\/|\/$/ig, '').split('/').pop()
        .replace(/[^a-z0-9]/ig, '_');
    var file = glob.sync('**/' + profileId + '-*.json', {cwd: project})[0];
    try {
        posts = JSON.parse(fs.readFileSync(file)) || [];
    }
    catch (e) {
        posts = []
    }
    return client
        .getUrl()
        .then(url =&gt; url !== profile
            ? client.url(profile)
            : client)
        .then(() =&gt; listFacebookPosts(posts.map(p =&gt; p.post)))
        // TODO: remove slice to download all posts from first part
        .then(r =&gt; importer.runAllPromises(r.map(c =&gt; (resolve) =&gt; {
            return (like ? likeFacebookPost(c) : client)
                .then(() =&gt; client.isExisting('//h3[contains(.,"Temporarily Blocked")]'))
                .then(is =&gt; {
                    if (is) like = null;
                    return scrapeFacebookPost(c);
                })
                .then(r =&gt; resolve(r))
                .catch(e =&gt; console.log(e))
        })))
        .then(t =&gt; {
            var filename = project + '/' + profileId
                + '-posts-' + (new Date()).getFullYear() + '.json';
            fs.writeFileSync(filename, JSON.stringify(t, null, 4));
            return t;
        })
        .catch(e =&gt; console.log(e))
};
module.exports = likeAllPosts;
</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>

<script>hljs.highlightAll();</script>

<p>This code snippet is designed to scrape Facebook posts and extract information from them. Here's a breakdown:</p>
<p><strong>Dependencies:</strong></p>
<ul>
<li><code>glob</code>: Used for file pattern matching (not directly used in the provided snippet).</li>
<li><code>importer</code>: A custom module for importing functionality (not shown).</li>
<li><code>fs</code>:  Node.js built-in module for file system operations (not directly used).</li>
</ul>
<p><strong>Variables:</strong></p>
<ul>
<li><code>PROFILE_PATH</code>:  Determines the user's home directory based on environment variables.</li>
<li><code>project</code>: Sets the path to a &quot;Conversations&quot; directory within the user's home directory.</li>
</ul>
<p><strong>Functions:</strong></p>
<ol>
<li><p><strong><code>listFacebookPosts(profile, posts = [])</code>:</strong></p>
<ul>
<li>Takes a <code>profile</code> (likely a Facebook profile URL) and an optional <code>posts</code> array (to store collected post URLs).</li>
<li>Uses a Puppeteer client (<code>client</code>) to:
<ul>
<li>Navigate to the Facebook profile.</li>
<li>Extract URLs of Facebook posts using XPath selectors (<code>//body// *[contains(@class, &quot;timestampContent&quot;)]/parent::*/parent::*/@href</code>).</li>
<li>Limit the number of extracted posts to 20.</li>
<li>Transform the extracted URLs to include &quot;https://www.facebook.com&quot; if they are missing.</li>
</ul></li>
<li>Handles potential errors during the process.</li>
</ul></li>
<li><p><strong><code>scrapeFacebookPost(post)</code>:</strong></p>
<ul>
<li>Takes a Facebook post URL (<code>post</code>).</li>
<li>Uses a Puppeteer client (<code>client</code>) to:
<ul>
<li>Navigate to the Facebook post URL.</li>
<li>Wait for a specific duration (4000ms for posts containing &quot;video&quot;, 2000ms otherwise).</li>
<li>Extract various information from the post using XPath selectors, including:
<ul>
<li>Post content (description).</li>
<li>Participants (user profiles).</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<p><strong>Purpose:</strong></p>
<p>This code snippet is part of a larger system for scraping Facebook posts and extracting relevant data. It automates the process of fetching post URLs and then scraping detailed information from each post.</p>
<p>Let me know if you have any other questions.</p>

</body>

</html>