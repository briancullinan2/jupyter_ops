<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>meta search all</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    html {
      padding: 0;
      margin: 0;
    }

    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
      padding: 10px;
    }

    body {
      padding: 0 0 0 200px;
      margin: 0;
    }

    .gold pre code,
    .gold pre code span,
    .gold code pre,
    .gold code pre span {
      color: gold;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <h3><a href="../data_collection/index.html">data collection</a></h3>
    <a href="./Crime_reports.html">Crime reports</a>
<br /><br />
<a href="./https___www_amazon_com_gp_yourstore_iyr_ref_pd_ys_iyr_nextie_UTF8_collection_watched_iyrGroup__maxIt.html">https://www.amazon.com/gp/yourstore/iyr/ref=pd_ys_iyr_nextie=UTF8&collection=watched&iyrGroup=&maxItem=616&minItem=600</a>
<br /><br />
<a href="./meta_search_all.html">meta search all</a>
<br /><br />
<a href="./schedule_search_all.html">schedule search all</a>
<br /><br />
<a href="./tell_joke.html">tell joke</a>
<br /><br />
<a href="./multi_crawl.html">multi crawl</a>
<br /><br />
<a href="./crawl_domain.html">crawl domain</a>
<br /><br />
<a href="./domain_cache_tools.html">domain cache tools</a>
<br /><br />
<a href="./browser_crawler_tools.html">browser crawler tools</a>
<br /><br />
<a href="./analyze_cache_file.html">analyze cache file</a>
<br /><br />
<a href="./schedule_crawl_domain.html">schedule crawl domain</a>
<br /><br />
<a href="./collect_all_bookmarks.html">collect all bookmarks</a>
<br /><br />
<a href="./search_results_as_json.html">search results as json</a>
<br /><br />

  </nav>
  <header>
    <a href="../data_collection/index.html">data collection</a> | <a href="./https___www_amazon_com_gp_yourstore_iyr_ref_pd_ys_iyr_nextie_UTF8_collection_watched_iyrGroup__maxIt.html">https://www.amazon.com/gp/yourstore/iyr/ref=pd_ys_iyr_nextie=UTF8&collection=watched&iyrGroup=&maxItem=616&minItem=600</a> | <a href="./schedule_search_all.html">schedule search all</a> | <a href="../../search.html">Search</a>
  </header>

  <p>The <code>searchAll</code> function is a main exported function that retrieves search results from multiple search engines in parallel using the <code>multiCrawl</code> function, and saves the results to a JSON file in the user's <code>Collections/searches</code> directory. The function takes an optional <code>query</code> parameter and returns a promise that resolves to an object containing search results, with the file name constructed from the query string and the current date.</p>
<h2>Run example</h2>

<pre language="bash"><code>npm run import -- "meta search all"</code></pre><h1>meta search all</h1>



<pre class="javascript"><code>var fs = require('fs');
var path = require('path');
var importer = require('../Core');
var multiCrawl = importer.import("<a href="../../Analytics/data_collection/multi_crawl.html">multi crawl</a>");

// http://www.exploratorium.edu/files/ronh/research/index.html
/*

 Exploratorium	
 Search
 Google	
 Search
 alltheweb	
 Search
 Teoma	
 Search
 AltaVista	
 Search
 Wisenut	
 Search
 HotBot	
 Search
 lii.org	
 Search
 Northern Light	
 Search
 Lycos	
 Search
 Scirus	
 
 Meta:
 Ask Jeeves	
 Search
 MetaCrawler	
 Search
 Dogpile	
 Search
 SavvySearch	
 
 
 */
var PROFILE_PATH = process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE || '';
var project = path.join(PROFILE_PATH, 'Collections/searches');

function searchAll(query = 'search engine') {
    var engines = [
        'https://www.google.com/search?q=' + query,
        'https://www.bing.com/search?q=' + query,
        'https://search.yahoo.com/search?p=' + query,
        'https://www.ask.com/web?q=' + query,
        'https://search.aol.com/aol/search?q=' + query,
        'http://www.baidu.com/s?wd=' + query,
        'https://www.wolframalpha.com/input/?i=' + query,
        'https://duckduckgo.com/?q=' + query,
        'https://www.yandex.com/search/?text=' + query,
        'https://archive.org/search.php?query=' + query,
    ];
    
    // TODO: save results
    return multiCrawl(engines, 'search results json')
        .then(r =&gt; {
            const time = new Date();
            fs.writeFileSync(path.join(project, query.replace(/[^a-z0-9]/ig, '_')
                                       + '-' + time.getFullYear()
                                       + '-' + (time.getMonth() + 1)
                                       + '-' + time.getDate()
                                       + '.json'), JSON.stringify(r, null, 4));
            return r;
        })
}
module.exports = searchAll;

if(typeof $ !== 'undefined') {
    $.async();
    searchAll()
        .then(r =&gt; $.sendResult(r))
        .catch(e =&gt; $.sendError(e))
}
</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="../../mergehtml.js"></script>

<script>
hljs.addPlugin(mergeHTMLPlugin);
hljs.highlightAll();
</script>

<div class="gold"><h2>What the code could have been:</h2>
<pre class="javascript"><code>const fs = require('fs').promises;
const path = require('path');
const multiCrawl = require('../Core').import('multi crawl');

const PROFILE_PATH = process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE || '';
const PROJECT_PATH = path.join(PROFILE_PATH, 'Collections','searches');

async function searchAll(query ='search engine') {
    try {
        const engines = [
            'https://www.google.com/search?q=' + encodeURIComponent(query),
            'https://www.bing.com/search?q=' + encodeURIComponent(query),
            'https://search.yahoo.com/search?p=' + encodeURIComponent(query),
            'https://www.ask.com/web?q=' + encodeURIComponent(query),
            'https://search.aol.com/aol/search?q=' + encodeURIComponent(query),
            'http://www.baidu.com/s?wd=' + encodeURIComponent(query),
            'https://www.wolframalpha.com/input/?i=' + encodeURIComponent(query),
            'https://duckduckgo.com/?q=' + encodeURIComponent(query),
            'https://www.yandex.com/search/?text=' + encodeURIComponent(query),
            'https://archive.org/search.php?query=' + encodeURIComponent(query),
        ];

        const results = await multiCrawl(engines,'search results json');
        const timestamp = new Date().toISOString().replace(/:/g, '-').replace('.', '-');
        const filename = query.replace(/[^a-z0-9]/ig, '_') + '-' + timestamp + '.json';
        const filePath = path.join(PROJECT_PATH, filename);

        await fs.writeFile(filePath, JSON.stringify(results, null, 4));
        return results;
    } catch (error) {
        throw error;
    }
}

module.exports = searchAll;

if (typeof $!== 'undefined') {
    $.async();
    searchAll()
       .then((results) => $.sendResult(results))
       .catch((error) => $.sendError(error));
}</code></pre></div><p><strong>Code Breakdown</strong></p>
<h3>Dependencies and Imports</h3>
<ul>
<li>The code requires the following dependencies:
<ul>
<li><code>fs</code> (File System) module</li>
<li><code>path</code> module</li>
<li>A custom module named <code>Core</code> located at <code>../Core</code></li>
</ul></li>
<li>It imports the <code>multiCrawl</code> function from the <code>Core</code> module using <code>importer.import('multi crawl')</code></li>
</ul>
<h3>Variables and Constants</h3>
<ul>
<li><code>PROFILE_PATH</code> is set to the user's home directory using various environment variables (<code>HOME</code>, <code>HOMEPATH</code>, <code>USERPROFILE</code>)</li>
<li><code>project</code> is the path to a directory named <code>Collections/searches</code> within the user's home directory</li>
<li>The <code>engines</code> array contains URLs for various search engines</li>
</ul>
<h3><code>searchAll</code> Function</h3>
<ul>
<li>This is the main function being exported</li>
<li>It takes an optional <code>query</code> parameter with a default value of <code>'search engine'</code></li>
<li>It returns a promise that resolves to an object containing search results</li>
<li>The function uses the <code>multiCrawl</code> function to crawl the search engines in parallel and retrieve their results</li>
<li>The results are then saved to a JSON file using <code>fs</code> and <code>path</code></li>
</ul>
<h3>File Saving</h3>
<ul>
<li>The file name is constructed by replacing non-alphanumeric characters in the <code>query</code> string with underscores, and appending the current date and year</li>
<li>The file is saved in the <code>Collections/searches</code> directory</li>
</ul>
<h3>Export and Usage</h3>
<ul>
<li>The <code>searchAll</code> function is exported as a module</li>
<li>If the <code>$</code> object is defined, it is used to send the search results or an error message</li>
</ul>

</body>

</html>