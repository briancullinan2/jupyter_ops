<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>Cell 4</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    html {
      padding: 0;
      margin: 0;
    }

    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
      padding: 10px;
    }

    body {
      padding: 0 0 0 200px;
      margin: 0;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <h3><a href="../llama_vision/index.html">llama vision</a></h3>
    <a href="./llama_vision.html">llama vision</a>
<br /><br />
<a href="./analyze_image_with_llm.html">analyze image with llm</a>
<br /><br />
<a href="./llm_deceive.html">llm deceive</a>
<br /><br />
<a href="./cell_3.html">Cell 3</a>
<br /><br />
<a href="./cell_4.html">Cell 4</a>
<br /><br />
<a href="./llm_voice.html">llm voice</a>
<br /><br />
<a href="./ollama_vision_request.html">ollama vision request</a>
<br /><br />
<a href="./start_a_bunch_of_llm_rpc_services.html">start a bunch of llm rpc services</a>
<br /><br />
<a href="./stable_diffusion_request.html">stable diffusion request</a>
<br /><br />
<a href="./mask_image.html">mask image</a>
<br /><br />
<a href="./inpaint_mask.html">inpaint mask</a>
<br /><br />
<a href="./image_2_image.html">image 2 image</a>
<br /><br />
<a href="./whisk_images.html">whisk images</a>
<br /><br />

  </nav>
  <header>
    <a href="../llama_vision/index.html">llama vision</a> | <a href="./cell_3.html">Cell 3</a> | <a href="./llm_voice.html">llm voice</a>
  </header>

  <p>The code sets up a text-to-speech (TTS) system using the <code>outetts</code> library, importing necessary modules and environment variables, and defining a function <code>generateSpeech</code> that generates speech from a given prompt. The <code>generateSpeech</code> function creates a TTS interface instance, loads a default speaker, generates speech, and saves the output to a WAV file.</p>
<h1>Cell 4</h1>



<pre class="javascript"><code>import path from 'path'
import process from 'process'
import { HFModelConfig_v1, InterfaceHF } from "outetts";

const HOMEPATH = process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE

// Configure the model
const model_config = new HFModelConfig_v1({
    model_path: 'OuteAI/OuteTTS-0.3-1B',
    language: "en", // Supported languages in v0.2: en, zh, ja, ko
    dtype: 'fp32', // Supported dtypes: fp32, q8, q4
})

let tts_interface
let speaker
async function generateSpeech(prompt) {
    // Initialize the interface
    if(!tts_interface) {
        tts_interface = await InterfaceHF({ model_version: "0.2", cfg: model_config })

        // Print available default speakers
        tts_interface.print_default_speakers()

        // Load a default speaker
        speaker = tts_interface.load_default_speaker("male_1")
    }

    // Generate speech
    const output = await tts_interface.generate({
        text: prompt,
        temperature: 0.1, // Lower temperature values may result in a more stable tone
        repetition_penalty: 1.1,
        //max_length: 4096,

        // Optional: Use a speaker profile for consistent voice characteristics
        // Without a speaker profile, the model will generate a voice with random characteristics
        speaker,
    })

    // Save the synthesized speech to a file
    output.save("output.wav")
}

export default generateSpeech
</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>

<script>hljs.highlightAll();</script>

<p><strong>Code Breakdown</strong></p>
<h3>Import Statements</h3>
<ul>
<li><code>import path from 'path'</code>: Imports the Node.js <code>path</code> module.</li>
<li><code>import process from 'process'</code>: Imports the Node.js <code>process</code> module.</li>
<li><code>import { HFModelConfig_v1, InterfaceHF } from &quot;outetts&quot;;</code>: Imports the <code>HFModelConfig_v1</code> and <code>InterfaceHF</code> classes from the <code>outetts</code> library.</li>
</ul>
<h3>Environment Variable Setup</h3>
<ul>
<li><code>const HOMEPATH = process.env.HOME || process.env.HOMEPATH || process.env.USERPROFILE</code>: Sets the <code>HOMEPATH</code> constant to the value of the <code>HOME</code>, <code>HOMEPATH</code>, or <code>USERPROFILE</code> environment variables.</li>
</ul>
<h3>Model Configuration</h3>
<ul>
<li><code>const model_config = new HFModelConfig_v1({...})</code>: Creates a new <code>HFModelConfig_v1</code> instance with the following properties:
<ul>
<li><code>model_path</code>: The path to the model file, set to <code>'OuteAI/OuteTTS-0.3-1B'</code>.</li>
<li><code>language</code>: The language code, set to <code>&quot;en&quot;</code>.</li>
<li><code>dtype</code>: The data type, set to <code>'fp32'</code>.</li>
</ul></li>
</ul>
<h3>Function Definitions</h3>
<ul>
<li><code>let tts_interface</code>: A variable to store the TTS interface instance.</li>
<li><code>let speaker</code>: A variable to store the speaker instance.</li>
<li><code>async function generateSpeech(prompt) {...}</code>: An asynchronous function that generates speech from a given prompt.</li>
</ul>
<h3>generateSpeech Function</h3>
<ul>
<li><code>if(!tts_interface) {...}</code>: Checks if the <code>tts_interface</code> instance is not created. If not, it creates a new instance using the <code>InterfaceHF</code> class.</li>
<li><code>tts_interface.print_default_speakers()</code>: Prints the available default speakers.</li>
<li><code>speaker = tts_interface.load_default_speaker(&quot;male_1&quot;)</code>: Loads a default speaker with the name <code>&quot;male_1&quot;</code>.</li>
<li><code>const output = await tts_interface.generate({...})</code>: Generates speech using the <code>generate</code> method of the <code>tts_interface</code> instance.</li>
<li><code>output.save(&quot;output.wav&quot;)</code>: Saves the synthesized speech to a file named <code>&quot;output.wav&quot;</code>.</li>
</ul>
<h3>Export Statement</h3>
<ul>
<li><code>export default generateSpeech</code>: Exports the <code>generateSpeech</code> function as the default export.</li>
</ul>

</body>

</html>