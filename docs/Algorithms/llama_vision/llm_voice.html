<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>llm voice</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    html {
      padding: 0;
      margin: 0;
    }

    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
      padding: 10px;
    }

    body {
      padding: 0 0 0 200px;
      margin: 0;
    }

    .gold pre code,
    .gold pre code span,
    .gold code pre,
    .gold code pre span {
      color: gold;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <h3><a href="../llama_vision/index.html">llama vision</a></h3>
    <a href="./llama_vision.html">llama vision</a>
<br /><br />
<a href="./analyze_image_with_llm.html">analyze image with llm</a>
<br /><br />
<a href="./llm_deceive.html">llm deceive</a>
<br /><br />
<a href="./cell_3.html">Cell 3</a>
<br /><br />
<a href="./cell_4.html">Cell 4</a>
<br /><br />
<a href="./llm_voice.html">llm voice</a>
<br /><br />
<a href="./cell_6.html">Cell 6</a>
<br /><br />
<a href="./ollama_vision_request.html">ollama vision request</a>
<br /><br />
<a href="./start_a_bunch_of_llm_rpc_services.html">start a bunch of llm rpc services</a>
<br /><br />
<a href="./stable_diffusion_request.html">stable diffusion request</a>
<br /><br />
<a href="./mask_image.html">mask image</a>
<br /><br />
<a href="./inpaint_mask.html">inpaint mask</a>
<br /><br />
<a href="./image_2_image.html">image 2 image</a>
<br /><br />
<a href="./whisk_images.html">whisk images</a>
<br /><br />

  </nav>
  <header>
    <a href="../llama_vision/index.html">llama vision</a> | <a href="./cell_4.html">Cell 4</a> | <a href="./cell_6.html">Cell 6</a> | <a href="../../search.html">Search</a>
  </header>

  <p>The code imports the OuteTTS library, configures a text-to-speech model, and defines a function <code>llmSpeech</code> to convert text to speech, which is then exposed to be used outside of this code module.</p>
<h2>Run example</h2>

<pre language="bash"><code>npm run import -- "llm voice"</code></pre><h1>llm voice</h1>



<pre class="python"><code>import outetts

# Configure the model
model_config = outetts.HFModelConfig_v2(
    model_path="OuteAI/OuteTTS-0.3-1B",
    tokenizer_path="OuteAI/OuteTTS-0.3-1B"
)

globals()["interface"] = None

def llmSpeech(prompt):

  if globals()["interface"] is None:
    # Initialize the interface
    interface = outetts.InterfaceHF(model_version="0.3", cfg=model_config)

    # You can create a speaker profile for voice cloning, which is compatible across all backends.
    # speaker = interface.create_speaker(audio_path="path/to/audio/file.wav")
    # interface.save_speaker(speaker, "speaker.json")
    # speaker = interface.load_speaker("speaker.json")

    # Print available default speakers
    interface.print_default_speakers()
    # Load a default speaker
    speaker = interface.load_default_speaker(name="en_male_1")

    globals()["interface"] = interface
    globals()["speaker"] = speaker
  else:
    interface = globals()["interface"]
    speaker = globals()["speaker"]

  # Generate speech
  gen_cfg = outetts.GenerationConfig(
      text=prompt,
      temperature=0.3,
      repetition_penalty=1.1,
      max_length=4096,
      speaker=speaker,
  )
  output = interface.generate(config=gen_cfg)

  # Save the generated speech to a file
  output.save("output.wav")

__all__ = {
  "llmSpeech": llmSpeech
}
</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="../../mergehtml.js"></script>

<script>
hljs.addPlugin(mergeHTMLPlugin);
hljs.highlightAll();
</script>

<div class="gold"><h2>What the code could have been:</h2>
<pre class="python"><code>import outetts

# Define the model configuration
class ModelConfig:
    """Configuration for the OuteTTS model"""
    def __init__(self, model_path, tokenizer_path):
        self.model_path = model_path
        self.tokenizer_path = tokenizer_path

    def to_dict(self):
        return {
            "model_path": self.model_path,
            "tokenizer_path": self.tokenizer_path
        }

# Define the speaker configuration
class SpeakerConfig:
    """Configuration for the speaker"""
    def __init__(self, name):
        self.name = name

    def to_dict(self):
        return {
            "name": self.name
        }

# Define the interface configuration
class InterfaceConfig:
    """Configuration for the OuteTTS interface"""
    def __init__(self, model_version):
        self.model_version = model_version

    def to_dict(self):
        return {
            "model_version": self.model_version
        }

# Define the generation configuration
class GenerationConfig:
    """Configuration for the speech generation"""
    def __init__(self, text, temperature, repetition_penalty, max_length, speaker):
        self.text = text
        self.temperature = temperature
        self.repetition_penalty = repetition_penalty
        self.max_length = max_length
        self.speaker = speaker

    def to_dict(self):
        return {
            "text": self.text,
            "temperature": self.temperature,
            "repetition_penalty": self.repetition_penalty,
            "max_length": self.max_length,
            "speaker": self.speaker
        }

# Define the OuteTTS interface
class OuteTTS:
    """Implementation of the OuteTTS interface"""
    def __init__(self, model_version, cfg):
        self.model_version = model_version
        self.cfg = cfg
        self.interface = None
        self.speaker = None

    def initialize(self):
        """Initialize the OuteTTS interface"""
        try:
            import torch
            import torchx
        except ImportError:
            print("Error: TTS and TorchX libraries are required")
            return

        try:
            self.interface = outetts.InterfaceHF(model_version=self.model_version, cfg=self.cfg)
        except Exception as e:
            print(f"Error: {e}")
            return

        try:
            # Create a speaker profile for voice cloning
            # self.speaker = self.interface.create_speaker(audio_path="path/to/audio/file.wav")
            # self.interface.save_speaker(speaker, "speaker.json")
            # self.speaker = self.interface.load_speaker("speaker.json")

            # Print available default speakers
            self.interface.print_default_speakers()
            # Load a default speaker
            self.speaker = self.interface.load_default_speaker(name="en_male_1")
        except Exception as e:
            print(f"Error: {e}")

        self.interface = self.interface
        self.speaker = self.speaker

    def generate(self, config):
        """Generate speech using the OuteTTS interface"""
        try:
            output = self.interface.generate(config=config)
        except Exception as e:
            print(f"Error: {e}")
            return

        return output

# Initialize the OuteTTS interface
def llmSpeech(prompt):
    """
    Generate speech using the OuteTTS interface

    Parameters:
    - prompt (str): Text to generate speech from

    Returns:
    - None
    """
    if not hasattr(llmSpeech, 'interface'):
        llmSpeech.interface = OuteTTS(model_version="0.3", cfg=ModelConfig(model_path="OuteAI/OuteTTS-0.3-1B", tokenizer_path="OuteAI/OuteTTS-0.3-1B"))
        llmSpeech.interface.initialize()
    else:
        llmSpeech.interface = llmSpeech.interface

    # Create a speaker profile for voice cloning
    # speaker = llmSpeech.interface.create_speaker(audio_path="path/to/audio/file.wav")
    # llmSpeech.interface.save_speaker(speaker, "speaker.json")
    # speaker = llmSpeech.interface.load_speaker("speaker.json")

    # Print available default speakers
    # llmSpeech.interface.print_default_speakers()
    # Load a default speaker
    speaker = llmSpeech.interface.speaker

    # Define the generation configuration
    config = GenerationConfig(
        text=prompt,
        temperature=0.3,
        repetition_penalty=1.1,
        max_length=4096,
        speaker=speaker
    )

    # Generate speech using the OuteTTS interface
    output = llmSpeech.interface.generate(config=config)

    # Save the generated speech to a file
    output.save("output.wav")

# Expose the llmSpeech function
__all__ = {
    "llmSpeech": llmSpeech
}</code></pre></div><h2>Code Breakdown</h2>
<h3>Importing the OuteTTS Library</h3>
<pre><code class="language-python">import outetts
</code></pre>
<p>The code imports the OuteTTS library, which is a text-to-speech (TTS) model.</p>
<h3>Configuring the Model</h3>
<pre><code class="language-python">model_config = outetts.HFModelConfig_v2(
    model_path=&quot;OuteAI/OuteTTS-0.3-1B&quot;,
    tokenizer_path=&quot;OuteAI/OuteTTS-0.3-1B&quot;
)
</code></pre>
<p>The code configures the model by specifying the paths to the model and tokenizer files.</p>
<h3>Defining the <code>llmSpeech</code> Function</h3>
<pre><code class="language-python">def llmSpeech(prompt):
</code></pre>
<p>The <code>llmSpeech</code> function takes a <code>prompt</code> parameter, which is the text to be converted into speech.</p>
<h3>Initializing the Interface</h3>
<pre><code class="language-python">if globals()[&quot;interface&quot;] is None:
    interface = outetts.InterfaceHF(model_version=&quot;0.3&quot;, cfg=model_config)
    #... (other interface initialization code)
</code></pre>
<p>The code checks if the <code>interface</code> variable is <code>None</code>. If it is, the interface is initialized with the specified model version and configuration.</p>
<h3>Loading a Default Speaker</h3>
<pre><code class="language-python"># Load a default speaker
speaker = interface.load_default_speaker(name=&quot;en_male_1&quot;)
</code></pre>
<p>The code loads a default speaker with the name &quot;en_male_1&quot;.</p>
<h3>Generating Speech</h3>
<pre><code class="language-python">gen_cfg = outetts.GenerationConfig(
    text=prompt,
    temperature=0.3,
    repetition_penalty=1.1,
    max_length=4096,
    speaker=speaker,
)
output = interface.generate(config=gen_cfg)
</code></pre>
<p>The code generates speech from the <code>prompt</code> text using the loaded speaker and configuration.</p>
<h3>Saving the Generated Speech</h3>
<pre><code class="language-python">output.save(&quot;output.wav&quot;)
</code></pre>
<p>The generated speech is saved to a file named &quot;output.wav&quot;.</p>
<h3>Exposing the <code>llmSpeech</code> Function</h3>
<pre><code class="language-python">__all__ = {
  &quot;llmSpeech&quot;: llmSpeech
}
</code></pre>
<p>The <code>llmSpeech</code> function is exposed to be used outside of this code module.</p>

</body>

</html>