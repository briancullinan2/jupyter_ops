<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>ask llm to write chapter titles and descriptions</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    html {
      padding: 0;
      margin: 0;
    }

    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
      padding: 10px;
    }

    body {
      padding: 0 0 0 200px;
      margin: 0;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <h3><a href="../llm_writing/index.html">llm writing</a></h3>
    <a href="./business_plan_llm.html">business plan llm</a>
<br /><br />
<a href="./write_creatively_llm.html">write creatively llm</a>
<br /><br />
<a href="./argue_with_multiple_llms.html">argue with multiple llms</a>
<br /><br />
<a href="./research_paper_llm.html">research paper llm</a>
<br /><br />
<a href="./select_llm.html">select llm</a>
<br /><br />
<a href="./ask_llm_to_write_chapter_titles_and_descriptions.html">ask llm to write chapter titles and descriptions</a>
<br /><br />
<a href="./ask_llm_to_brainstorm.html">ask llm to brainstorm</a>
<br /><br />
<a href="./write_a_grant_proposal_with_llm.html">write a grant proposal with llm</a>
<br /><br />
<a href="./decode_xlsx_spreadsheet.html">decode xlsx spreadsheet</a>
<br /><br />
<a href="./elaborate_list_with_llm.html">elaborate list with llm</a>
<br /><br />

  </nav>
  <header>
    <a href="../llm_writing/index.html">llm writing</a> | <a href="./select_llm.html">select llm</a> | <a href="./ask_llm_to_brainstorm.html">ask llm to brainstorm</a> | <a href="../../search.html">Search</a>
  </header>

  <p>The <code>askLlamaForAChapterSynopsis</code> function asynchronously generates a list of chapter or character synopses for a given topic by interacting with an LLM (Large Language Model), logging the user's prompt and the LLM's response, and parsing the response to extract the synopsis titles and descriptions. The function returns an object with key-value pairs representing the synopses, assuming the LLM's response contains a list of numbered titles followed by their descriptions.</p>
<h2>Run example</h2>

<pre language="bash"><code>npm run import -- "ask llm to write chapter titles and descriptions"</code></pre><h1>ask llm to write chapter titles and descriptions</h1>



<pre class="javascript"><code>

// TODO: parse title from descriptions and return in a nicely formatted object array
async function askLlamaForAChapterSynopsis(topic, chapterOrCharacterOrSections = 'chapters') {
  const {llmPrompt} = await importer.import("<a href="../../Algorithms/llama/create_llm_session.html">create llm session</a>")

  let q1 = 'Brainstorm a list of 12 ' + chapterOrCharacterOrSections + ' synopsis:\n' 
    + topic + '\nRespond with the numbered titles followed by the description.'

  console.log("User: " + q1);
  const a1 = await llmPrompt(q1);
  console.log("AI: " + a1);

  let titles = a1.trim().split(/(^|\n)\s*[0-9]+\.\s*/gi)
    .filter(a =&gt; a &amp;&amp; a.trim().length &gt; 0)
  let obj = {}
  for(let i = 0; i &lt; titles.length; i++) {
    if(topic.includes(titles[i]) &amp;&amp; titles[i+1].length &lt; 128) continue;
    let lines = titles[i].split(/\*\*|\#\#|\n/gi).filter(a =&gt; a &amp;&amp; a.trim().length &gt; 0)
    let key = lines[0]
    obj[key] = lines.slice(1).join('\n')
    if(obj[key].length == 0 &amp;&amp; titles[i+1].length &gt; 128) {
      obj[key] = titles[i+1]
      i++
    }
  }
  console.log(obj)
  return obj
}

module.exports = askLlamaForAChapterSynopsis
</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="../../mergehtml.js"></script>

<script>
hljs.addPlugin(mergeHTMLPlugin);
hljs.highlightAll();
</script>

<h2>Function Breakdown</h2>
<h3><code>askLlamaForAChapterSynopsis(topic, chapterOrCharacterOrSections = 'chapters')</code></h3>
<ul>
<li><strong>Purpose:</strong> Asynchronously generates a list of chapter or character synopses for a given topic.</li>
<li><strong>Parameters:</strong>
<ul>
<li><code>topic</code>: The topic for which synopses are generated.</li>
<li><code>chapterOrCharacterOrSections</code>: The type of synopses to generate. Defaults to <code>'chapters'</code>.</li>
</ul></li>
<li><strong>Return Value:</strong> An object with key-value pairs representing the synopses.</li>
</ul>
<h2>Function Flow</h2>
<ol>
<li><strong>LLM Session Creation:</strong> Imports an LLMPrompt object from a module named <code>create llm session</code>.</li>
<li><strong>Prompt Generation:</strong> Creates a prompt for the LLM to generate a list of synopsis titles and descriptions.</li>
<li><strong>LLM Response:</strong> Sends the prompt to the LLM and logs the LLM's response.</li>
<li><strong>Synopsis Extraction:</strong> Extracts the synopsis titles and descriptions from the LLM's response.</li>
<li><strong>Object Construction:</strong> Constructs an object with key-value pairs representing the synopses.</li>
<li><strong>Logging and Return:</strong> Logs the constructed object and returns it.</li>
</ol>
<h2>Notes</h2>
<ul>
<li>The function logs the user's prompt and the LLM's response for debugging purposes.</li>
<li>The function uses several regular expressions to parse the LLM's response and extract the synopsis titles and descriptions.</li>
<li>The function assumes that the LLM's response contains a list of numbered titles followed by their descriptions.</li>
</ul>

</body>

</html>