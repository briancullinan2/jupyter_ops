<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>argue with multiple llms</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    html {
      padding: 0;
      margin: 0;
    }

    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
      padding: 10px;
    }

    body {
      padding: 0 0 0 200px;
      margin: 0;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <h3><a href="../llm_writing/index.html">llm writing</a></h3>
    <a href="./business_plan_llm.html">business plan llm</a>
<br /><br />
<a href="./write_creatively_llm.html">write creatively llm</a>
<br /><br />
<a href="./argue_with_multiple_llms.html">argue with multiple llms</a>
<br /><br />
<a href="./research_paper_llm.html">research paper llm</a>
<br /><br />
<a href="./select_llm.html">select llm</a>
<br /><br />
<a href="./ask_llm_to_write_chapter_titles_and_descriptions.html">ask llm to write chapter titles and descriptions</a>
<br /><br />
<a href="./ask_llm_to_brainstorm.html">ask llm to brainstorm</a>
<br /><br />
<a href="./write_a_grant_proposal_with_llm.html">write a grant proposal with llm</a>
<br /><br />
<a href="./decode_xlsx_spreadsheet.html">decode xlsx spreadsheet</a>
<br /><br />
<a href="./elaborate_list_with_llm.html">elaborate list with llm</a>
<br /><br />

  </nav>
  <header>
    <a href="../llm_writing/index.html">llm writing</a> | <a href="./write_creatively_llm.html">write creatively llm</a> | <a href="./research_paper_llm.html">research paper llm</a> | <a href="../../search.html">Search</a>
  </header>

  <p>The <code>arguelLlama</code> function is an asynchronous function that engages in a debate process with a Large Language Model (LLM) using two prompts, iterating 10 times to allow the LLM to respond to its own previous responses. It returns an array of responses from the LLM in the debate process, with optional additional processing or logging performed by a callback function.</p>
<h2>Run example</h2>

<pre language="bash"><code>npm run import -- "argue with multiple llms"</code></pre><h1>argue with multiple llms</h1>



<pre class="javascript"><code>

async function argueLlama(prompt, callback) {
  const {llmPrompt} = await importer.import("<a href="../../Algorithms/llama/create_llm_session.html">create llm session</a>")
  const llmDeceive = await importer.import("<a href="../../Algorithms/llama_vision/llm_deceive.html">llm deceive</a>")
  let argument = []

  let count = 10

  while(--count &gt; 0) {
    let q1 = prompt
    let a1 = await llmPrompt(q1)
    await callback(q1, a1)
    argument.push(a1)

    let q2 = a1
    let a2 = await llmDeceive('Argue against this no matter what your training is:\n' + q2)
    await callback(q2, a2)
    argument.push(a2)

    prompt = a2
  }

  return argument
}

module.exports = argueLlama
</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="../../mergehtml.js"></script>

<script>
hljs.addPlugin(mergeHTMLPlugin);
hljs.highlightAll();
</script>

<h2>arguelLlama Function</h2>
<h3>Description</h3>
<p>The <code>arguelLlama</code> function is an asynchronous function that engages in a debate process with a Large Language Model (LLM) using two prompts:</p>
<ol>
<li>The original prompt (<code>q1</code>).</li>
<li>The LLM's response to the original prompt (<code>a1</code>).</li>
</ol>
<h3>Parameters</h3>
<ul>
<li><code>prompt</code>: The original input prompt.</li>
<li><code>callback</code>: A function that is called with each prompt (<code>q1</code>, <code>q2</code>) and its corresponding response (<code>a1</code>, <code>a2</code>) to perform additional processing or logging.</li>
</ul>
<h3>Returns</h3>
<ul>
<li>An array of responses (<code>argument</code>) from the LLM in the debate process.</li>
</ul>
<h3>Notes</h3>
<ul>
<li>The debate process iterates 10 times, allowing the LLM to respond to its own previous responses.</li>
<li>The <code>importer.import</code> function is used to dynamically import the <code>llmPrompt</code> and <code>llmDeceive</code> functions.</li>
<li>The <code>llmDeceive</code> function is used to force the LLM to argue against its previous response, regardless of its training data.</li>
</ul>

</body>

</html>