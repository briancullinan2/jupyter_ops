<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>store all notebook llm functions</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
    }

    body {
      padding-left: 200px;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <a href="../llama/index.html">llama</a>
    <br /><br />
    <a href="./search_llama.html">search llama</a>
<br /><br />
<a href="./ask_llm_about_categories.html">ask llm about categories</a>
<br /><br />
<a href="./ask_llm_to_generalize_categories.html">ask llm to generalize categories</a>
<br /><br />
<a href="./ask_llm_for_a_shorter_list_of_categories.html">ask llm for a shorter list of categories</a>
<br /><br />
<a href="./ask_llm_about_functions.html">ask llm about functions</a>
<br /><br />
<a href="./ask_llm_about_code.html">ask llm about code</a>
<br /><br />
<a href="./ask_llm_about_notebooks.html">ask llm about notebooks</a>
<br /><br />
<a href="./ask_llm_to_summerize.html">ask llm to summerize</a>
<br /><br />
<a href="./store_llama_function.html">store llama function</a>
<br /><br />
<a href="./store_all_notebook_llm_functions.html">store all notebook llm functions</a>
<br /><br />
<a href="./create_llm_session.html">create llm session</a>
<br /><br />

  </nav>
  <header>
    <a href="../llama/index.html">llama</a> ${PREV} ${NEXT}
  </header>

  <p>Here's a summary of the code breakdown in two sentences:</p>
<p>The code imports several modules and functions, including LLM functions to summarize and generalize code, and uses an async function <code>storeAllLlamaFunctions</code> to store all LLM functions. The <code>storeAllLlamaFunctions</code> function retrieves code from the cache, checks conditions, and updates the cache using LLM functions when necessary, while also performing operations on a <code>functionCache</code> object to store cached descriptions and summaries.</p>


<pre class="javascript"><code>const {askLlamaAboutCode} = importer.import('ask llm about code')
const {askLlamaToSummerize, askLlamaToGeneralize} = importer.import('ask llm to summerize')
const {getExports, cacheCells} = importer.import([
  'select code tree', 'get exports from source', 'cache notebook', 'cache all'])
const { functionCache } = importer.import('cache rpc functions with llm descriptions')
const { storeLlamaFunction } = importer.import('store llama function')

async function storeAllLlamaFunctions() {
  const getParameters = await importer.import('get c parameters')
  const pythonParams = await importer.import('python params in antlr')
  let cellCache = importer.import('cell cache').cellCache
  for(let i = 0; i < cellCache.length; i++) {
    let cell = cellCache[i]
    //if(!cell[2].questions || !cell[2].questions[0]) continue
    let code = importer.lookupCell(cell[1], cacheCells)
    if(code.code.trim().length == 0) {
      storeLlamaFunction(cell[1], code.mtime, [], '', '', '', '')
      continue
    }

    let summary
    let shortened
    let rpcFunction
    let categories
    let category
    let fresh = false

    if(typeof functionCache[cell[1]] != 'undefined') {
      if(
        // notebook hasn't changed
        code.mtime <= functionCache[cell[1]].mtime
        // don't both updating cache notebooks, 
        // otherwise this will run every time any notebook changes
        || code.filename.match(/cache/gi)
      ) {
        summary = functionCache[cell[1]].description
        shortened = functionCache[cell[1]].summary
        rpcFunction = functionCache[cell[1]].exports
      }

      categories = functionCache[cell[1]].categories
      category = functionCache[cell[1]].categories
    } else {
      fresh = true
    }

    // needs cleanup
    if(!summary || !categories || (categories + '').includes('\n')
      || summary.length < 256 || summary.match(/Find the derivative/gi) 
      || shortened.match(/Find the derivative/gi)
      || categories.match(/Code analysis request/gi)) {
      // TODO: this should cause the erroneous cell to show up every time and for these to be fixed next pass
      summary = await askLlamaAboutCode(code.code)
      shortened = await askLlamaToSummerize(summary)
      categories = await askLlamaToGeneralize(summary)
      fresh = true
    }
    if(typeof rpcFunction == 'undefined') {
      try {
        if(code.language == 'javascript')
          rpcFunction = getExports(code.code)
        if(code.language == 'c' || code.language == 'cpp')
          rpcFunction = (await getParameters(code.code)).map(p => typeof p == 'string' ? p : p[0])
        if(code.language == 'python') {
          const params = await pythonParams(code.code)
          rpcFunction = typeof params.function != 'undefined' ? [params.function] : params.map(p => p.function)
        }
        fresh = true
      } catch (e) {
        rpcFunction = []
      }
    }

    if(fresh) {
      // TODO: insert rpc function into sqlite database to make subsequent lookups faster
      storeLlamaFunction(cell[1], code.mtime, rpcFunction, summary, shortened, categories, category)
    }
  }
}

module.exports = {
  storeAllLlamaFunctions
}</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>

<script>hljs.highlightAll();</script>

<h3>Code Breakdown</h3>
<h4>Imported Modules</h4>
<p>The code imports several modules using the <code>importer</code> object:</p>
<ul>
<li><code>askLlamaAboutCode</code>: a function to ask the LLM about code</li>
<li><code>askLlamaToSummerize</code> and <code>askLlamaToGeneralize</code>: functions to summarize and generalize code, respectively</li>
<li><code>getExports</code>, <code>cacheCells</code>: functions to get exports and cache cells</li>
<li><code>functionCache</code>: a function to cache RPC functions with LLM descriptions</li>
<li><code>storeLlamaFunction</code>: a function to store LLM functions</li>
</ul>
<h4><code>storeAllLlamaFunctions</code> Function</h4>
<p>The <code>storeAllLlamaFunctions</code> function is an asynchronous function that stores all LLM functions. It:</p>
<ol>
<li>Imports the <code>getParameters</code> and <code>pythonParams</code> modules.</li>
<li>Retrieves the <code>cellCache</code> array from the <code>cell cache</code> module.</li>
<li>Iterates through the <code>cellCache</code> array and for each cell:
<ul>
<li>Retrieves the code from the cache using <code>cacheCells</code>.</li>
<li>Checks if the code is empty. If so, stores an empty LLM function.</li>
<li>Retrieves summary, shortened code, RPC function, categories, and category from the <code>functionCache</code> object. If not found, sets flags to indicate a fresh cache.</li>
<li>Checks if the retrieved summary, categories, or RPC function meet certain conditions (e.g., length, pattern matching). If not, updates the cache using the LLM functions.</li>
</ul></li>
</ol>
<h4>Function Cache Operations</h4>
<p>The code performs the following operations on the <code>functionCache</code> object:</p>
<ul>
<li>Retrieves the cached description, summary, RPC function, categories, and category for a cell.</li>
<li>Updates the cache with a new description, summary, RPC function, categories, and category if the conditions are not met.</li>
</ul>
<h4>Notes</h4>
<ul>
<li>The code contains TODO comments indicating areas that require cleanup or refactoring.</li>
<li>The <code>functionCache</code> object appears to be used to cache RPC functions with LLM descriptions. However, the exact logic behind its usage is unclear without additional context.</li>
<li>The <code>cellCache</code> array is used to iterate through cells, but its contents and structure are not explicitly described.</li>
</ul>

</body>

</html>