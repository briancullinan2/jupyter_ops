<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>ask llm about chat conversations</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
    }

    body {
      padding-left: 200px;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <a href="../llm_tools/index.html">llm tools</a>
    <br /><br />
    <a href="./scan_chat_logs.html">scan chat logs</a>
<br /><br />
<a href="./ask_llm_about_emotions.html">ask llm about emotions</a>
<br /><br />
<a href="./cache_chat_logs.html">cache chat logs</a>
<br /><br />
<a href="./ask_llm_about_chat_conversations.html">ask llm about chat conversations</a>
<br /><br />
<a href="./llm_respond_like_a_personality.html">llm respond like a personality</a>
<br /><br />

  </nav>
  <header>
    <a href="../llm_tools/index.html">llm tools</a> ${PREV} ${NEXT}
  </header>

  <p>Here's a 2-sentence summary of the code:</p>
<p>The code consists of two asynchronous functions, <code>askLlamaAboutConversation</code> and <code>askLlamaAboutCategory</code>, which interact with a Large Language Model (LLM) to gather information about a conversation and categorize it based on the conversation. Both functions import the LLM prompt function from a separate module, prompt the LLM with a user-defined question, and return the LLM's response after processing it for whitespace, punctuation, and special characters.</p>


<pre class="javascript"><code>
async function askLlamaAboutConversation(currentMessages) {
  const {llmPrompt} = await importer.import('create llm session')
  let q1 = 'Can you summarize in two sentences what this conversation is about:\n' + 
  currentMessages.join('\n') + '\nPlease discard any pleasantries, documentation only.'
  console.log("User: " + q1);
  const a1 = await llmPrompt(q1);
  console.log("AI: " + a1);
  return a1.trim()
}

async function askLlamaAboutCategory(currentMessages) {
  const {llmPrompt} = await importer.import('create llm session')
  let q1 = 'Categorize this conversation in two or three words:\n' + 
  currentMessages.join('\n') + '\nOnly respond with the category.'
  console.log("User: " + q1);
  const a1 = await llmPrompt(q1);
  console.log("AI: " + a1);
  return a1.trim().split(/\s*\n\s*|,\s*|\s*- |\s*\* /gi)[0]
}

module.exports = {
  askLlamaAboutConversation,
  askLlamaAboutCategory
}

</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>

<script>hljs.highlightAll();</script>

<h3>Code Breakdown</h3>
<p>This code consists of two asynchronous functions, <code>askLlamaAboutConversation</code> and <code>askLlamaAboutCategory</code>, which interact with a Large Language Model (LLM) to gather information about a conversation.</p>
<h4>Function 1: <code>askLlamaAboutConversation</code></h4>
<ul>
<li>Prompts the LLM to summarize the conversation in two sentences.</li>
<li>Expects the LLM to discard any pleasantries and only provide documentation.</li>
<li>Returns the LLM's response after trimming any unnecessary whitespace.</li>
</ul>
<h4>Function 2: <code>askLlamaAboutCategory</code></h4>
<ul>
<li>Prompts the LLM to categorize the conversation in two or three words.</li>
<li>Expects the LLM to only respond with the category.</li>
<li>Returns the first word of the LLM's response, trimmed and cleaned of any whitespace, punctuation, or special characters.</li>
</ul>
<h4>Module Exports</h4>
<p>Both functions are exported as part of a module, allowing them to be used in other parts of the application.</p>
<h3>Function Signature</h3>
<pre><code class="language-javascript">async function askLlamaAboutConversation(currentMessages) {
  //...
}

async function askLlamaAboutCategory(currentMessages) {
  //...
}

module.exports = {
  askLlamaAboutConversation,
  askLlamaAboutCategory
}
</code></pre>
<h3>Parameters</h3>
<p>Both functions expect an array of strings, <code>currentMessages</code>, as input.</p>
<h3>Return Values</h3>
<ul>
<li><code>askLlamaAboutConversation</code> returns a string containing the LLM's response after trimming whitespace.</li>
<li><code>askLlamaAboutCategory</code> returns a string containing the first word of the LLM's response after trimming and cleaning.</li>
</ul>
<h3>LLM Interaction</h3>
<ul>
<li>The <code>llmPrompt</code> function is imported from a module using the <code>importer</code> object.</li>
<li>The LLM is prompted with a user-defined question, which is then logged to the console.</li>
<li>The LLM's response is logged to the console and returned as the function's result.</li>
</ul>

</body>

</html>