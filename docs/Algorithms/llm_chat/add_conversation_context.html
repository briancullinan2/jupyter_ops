<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>add conversation context</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    html {
      padding: 0;
      margin: 0;
    }

    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
      padding: 10px;
    }

    body {
      padding: 0 0 0 200px;
      margin: 0;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <h3><a href="../llm_chat/index.html">llm chat</a></h3>
    <a href="./store_llm_response.html">store llm response</a>
<br /><br />
<a href="./general_chit_chat.html">general chit chat</a>
<br /><br />
<a href="./relevant_llm_history.html">relevant llm history</a>
<br /><br />
<a href="./relevant_chat_keywords.html">relevant chat keywords</a>
<br /><br />
<a href="./relevant_history_timestamps.html">relevant history timestamps</a>
<br /><br />
<a href="./classify_llm_prompt.html">classify llm prompt</a>
<br /><br />
<a href="./handle_conversation.html">handle conversation</a>
<br /><br />
<a href="./add_conversation_context.html">add conversation context</a>
<br /><br />
<a href="./llm_load_memories.html">llm load memories</a>
<br /><br />
<a href="./llm_save_memories.html">llm save memories</a>
<br /><br />

  </nav>
  <header>
    <a href="../llm_chat/index.html">llm chat</a> | <a href="./handle_conversation.html">handle conversation</a> | <a href="./llm_load_memories.html">llm load memories</a> | <a href="../../search.html">Search</a>
  </header>

  <p>The <code>classifyPrompt</code> function takes a prompt and image as input, matches the prompt to a specific function, and executes that function with the provided arguments to generate a response. The function iterates over matching functions, imports and parameterizes each one, and returns the result with additional memories, except for the <code>doStableRequest</code> function which returns a combined object.</p>
<h2>Run example</h2>

<pre language="bash"><code>npm run import -- "add conversation context"</code></pre><h1>add conversation context</h1>



<pre class="javascript"><code>const { messageRecents } = importer.import("<a href="../../Algorithms/llm_chat/general_chit_chat.html">general chit chat</a>")
const {doStableRequest} = importer.import("<a href="../../Algorithms/llama_vision/stable_diffusion_request.html">stable diffusion request</a>")
//const messageOllamaVision = importer.import("<a href="../../Algorithms/llama_vision/image_2_image.html">describe an image</a>")
const {askLlamaMatchingFunction, API_DESCRIPTION} = importer.import("<a href="../../Algorithms/llm_chat/classify_llm_prompt.html">classify llm prompt</a>")
const getParameters = importer.import("<a href="../../Core/syntax/get_parameter_names.html">function parameters</a>")
const {listMemories} = importer.import("<a href="../../Algorithms/llm_chat/llm_load_memories.html">llm load memories</a>")

async function classifyPrompt(promptModel, session, prompt, image, otr) {

  let matchingFunctions = await askLlamaMatchingFunction(promptModel, prompt, image)

  let importedFunction
  let answer = ''
  let context = {
    promptModel, session, prompt, image, otr
  }

  // drop out early if the matching function is ourselves, this is how we return our function description for inquiries about capabilities.
  if(matchingFunctions == classifyPrompt) {
    return {
      memories: await listMemories(session),
      content: 'Given the following functions:\n' + API_DESCRIPTION
    }
  }

  //let historyFiles = await relevantHistory(promptModel, session, prompt)

  // TODO: convert to available parameters like Core/import.ipynb:run() style parameterization
  for (let i = 0; i &lt; matchingFunctions.length; i++) {
    importedFunction = importer.import("<a href="../../Algorithms/opencv/motion_detection.html">matchingFunctions[i</a>")
    if (typeof importedFunction == 'object' &amp;&amp; typeof Object.values(importedFunction)[0] == 'function') {
      importedFunction = Object.values(importedFunction)[0]
    }
    // call parameterized
    let params = getParameters(importedFunction.toString()).slice(1)
    let inputs = []
    for(let j = 0; j &lt; params.length; j++)
      inputs[j] = context[params[j]]
    answer = await importedFunction.apply(null, inputs)
    break
  }

  if(importedFunction == doStableRequest) {
    return Object.assign(answer, {
      memories: await listMemories(session),
      content: await messageRecents(session, prompt)
    })
  } else if (importedFunction != messageRecents) {
    if(typeof answer == 'object') {
      return Object.assign({}, {
        memories: await listMemories(session),
        content: await messageRecents(session, prompt)
      }, answer)
    } else {
      return {
        memories: await listMemories(session),
        content: (answer ? answer : '') + await messageRecents(session, prompt)
      }
    }
  } else {
    return {
      memories: await listMemories(session),
      content: answer ? answer : await messageRecents(session, prompt)
    }
  }

}

module.exports = classifyPrompt

</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="../../mergehtml.js"></script>

<script>
hljs.addPlugin(mergeHTMLPlugin);
hljs.highlightAll();
</script>

<h2>Code Breakdown</h2>
<h3>Import Statements</h3>
<p>The code imports various functions and variables from different modules:</p>
<ul>
<li><code>messageRecents</code>, <code>listMemories</code>, and <code>API_DESCRIPTION</code> from <code>general chit chat</code>, <code>llm load memories</code>, and an unspecified module, respectively.</li>
<li><code>doStableRequest</code> from <code>stable diffusion request</code>.</li>
<li><code>askLlamaMatchingFunction</code> and <code>getParameters</code> from <code>classify llm prompt</code> and an unspecified module, respectively.</li>
</ul>
<h3><code>classifyPrompt</code> Function</h3>
<p>The <code>classifyPrompt</code> function takes five arguments:</p>
<ul>
<li><code>promptModel</code></li>
<li><code>session</code></li>
<li><code>prompt</code></li>
<li><code>image</code></li>
<li><code>otr</code></li>
</ul>
<p>This function appears to match a given prompt to a specific function and execute that function with the provided arguments. Here's a step-by-step breakdown:</p>
<ol>
<li><strong>Match Function</strong>: It calls <code>askLlamaMatchingFunction</code> to find a matching function for the given prompt and image.</li>
<li><strong>Return Function Description</strong>: If the matching function is <code>classifyPrompt</code> itself, it returns a description of the <code>classifyPrompt</code> function, including its capabilities and a list of memories.</li>
<li><strong>Iterate Matching Functions</strong>: It iterates over the matching functions and attempts to import each one using <code>importer.import</code>.</li>
<li><strong>Parameterize Function</strong>: For each imported function, it extracts its parameters using <code>getParameters</code> and sets their values from the <code>context</code> object.</li>
<li><strong>Execute Function</strong>: It calls the imported function with the parameterized inputs and stores the result in <code>answer</code>.</li>
<li><strong>Special Handling</strong>: If the executed function is <code>doStableRequest</code>, it returns a combined object with the function's result, memories, and recent messages. Otherwise, it returns the function's result with additional memories.</li>
</ol>
<p>Note that the code has a few TODO comments and appears to be in the process of being refactored.</p>

</body>

</html>