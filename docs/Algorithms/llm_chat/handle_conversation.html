<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv='X-UA-Compatible' content='IE=edge'>
  <title>handle conversation</title>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link rel='stylesheet' type='text/css' media='screen' href='main.css'>
  <style>
    nav {
      position: fixed;
      overflow: auto;
      top: 0;
      left: 0;
      right: auto;
      bottom: 0;
      width: 200px;
    }

    header {
      background-color: #EEE;
    }

    body {
      padding-left: 200px;
    }

    @media screen and (max-width: 600px) {
      body {
        padding-left: 0;
      }

      nav {
        display: none;
      }
    }
  </style>
</head>

<body>
  <nav>
    <a href="../llm_chat/index.html">llm chat</a>
    <br /><br />
    <a href="./store_llm_response.html">store llm response</a>
<br /><br />
<a href="./general_chit_chat.html">general chit chat</a>
<br /><br />
<a href="./relevant_llm_history.html">relevant llm history</a>
<br /><br />
<a href="./relevant_chat_keywords.html">relevant chat keywords</a>
<br /><br />
<a href="./relevant_history_timestamps.html">relevant history timestamps</a>
<br /><br />
<a href="./classify_llm_prompt.html">classify llm prompt</a>
<br /><br />
<a href="./handle_conversation.html">handle conversation</a>
<br /><br />
<a href="./add_conversation_context.html">add conversation context</a>
<br /><br />
<a href="./llm_load_memories.html">llm load memories</a>
<br /><br />
<a href="./llm_save_memories.html">llm save memories</a>
<br /><br />

  </nav>
  <header>
    <a href="../llm_chat/index.html">llm chat</a> ${PREV} ${NEXT}
  </header>

  <p>Here is a 2-sentence summary of the provided code:</p>
<p>The <code>handleConversation</code> function is an asynchronous function that handles a conversation by classifying the prompt, storing the response, generating a response from a language model, and storing the final response. It takes five parameters, including <code>promptModel</code>, <code>session</code>, <code>prompt</code>, <code>image</code>, and <code>otr</code>, and returns the final response after processing the language model's output and storing relevant information.</p>


<pre class="javascript"><code>const classifyPrompt = importer.import('add conversation context')
const storeResponse = importer.import('store llm response')

async function handleConversation(promptModel, session, prompt, image, otr) {
  let context = await classifyPrompt(promptModel, session, prompt, image)

  let messageStorage = await storeResponse(true, session, prompt, 
    context.content + (context.memories ? ('\nApply any relevant memories to your reponse:\n' + context.memories.join('\n')) : ''), 
    otr)

  let q1 = (context && context.content ? context.content : '') 
  + (context.image ? '\nThe response image is provided.\n' : '')
  + '\nRespond to this message and pretend to be emotional (e.g. ' 
  + messageStorage.emotions.join(', ') + '):\n' 
  + prompt
  + (context.memories ? ('\nApply any relevant memories to your reponse:\n' + context.memories.join('\n')) : '')
  console.log('User: ' + q1)
  let result = await promptModel(q1)

  if(context.imagePath) {
    if(result.match(/!\[[^\]]*\]\((.*?)\s*("(?:.*[^"])")?\s*\)/gi)) {
      result = result.replace(/!\[[^\]]*\]\((.*?)\s*("(?:.*[^"])")?\s*\)/gi, 
        // TODO: accomodate discord by removing the markdown? 
        //   or providing a server address to brian-chat? 
        //   return entire context with result to doMention()?
        '![' + context.prompt + '](/' + context.imagePath.replaceAll(' ', '%20') + ')')
    } else {
      result += '\n\n![' + context.prompt + '](/' + context.imagePath.replaceAll(' ', '%20') + ')'
    }
  }

  if(session) {
    await storeResponse(false, session, result, void 0, otr)
  }

  return result
}

module.exports = handleConversation

</code></pre>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.css">


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- and it's easy to individually load additional languages -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>

<script>hljs.highlightAll();</script>

<h2>Code Breakdown</h2>
<h3>Import Statements</h3>
<pre><code class="language-javascript">const classifyPrompt = importer.import('add conversation context')
const storeResponse = importer.import('store llm response')
</code></pre>
<ul>
<li>These lines import two functions from a module: <code>classifyPrompt</code> and <code>storeResponse</code>.</li>
<li><code>classifyPrompt</code> is related to adding conversation context, while <code>storeResponse</code> is related to storing responses from a language model.</li>
</ul>
<h3>handleConversation Function</h3>
<pre><code class="language-javascript">async function handleConversation(promptModel, session, prompt, image, otr) {
  //...
}
</code></pre>
<ul>
<li>This is an asynchronous function named <code>handleConversation</code>.</li>
<li>It takes five parameters: <code>promptModel</code>, <code>session</code>, <code>prompt</code>, <code>image</code>, and <code>otr</code>.</li>
<li>The function's purpose is to handle a conversation by classifying the prompt, storing the response, and generating a response from a language model.</li>
</ul>
<h3>Function Body</h3>
<ol>
<li><p><strong>Classifying the Prompt</strong></p>
<pre><code class="language-javascript"></code></pre></li>
</ol>
<p>let context = await classifyPrompt(promptModel, session, prompt, image)</p>
<pre><code>
   * The function `classifyPrompt` is called with the provided parameters to classify the prompt.
   * The result is stored in the variable `context`.

2. **Storing the Response**

   ```javascript
let messageStorage = await storeResponse(true, session, prompt, 
  context.content + (context.memories? ('\nApply any relevant memories to your reponse:\n' + context.memories.join('\n')) : ''), 
  otr)
</code></pre>
<ul>
<li>The function <code>storeResponse</code> is called with the provided parameters to store the response.</li>
<li>The result is stored in the variable <code>messageStorage</code>.</li>
</ul>
<ol start="3">
<li><p><strong>Generating the Response</strong></p>
<pre><code class="language-javascript"></code></pre></li>
</ol>
<p>let q1 = (context &amp;&amp; context.content? context.content : '')</p>
<ul>
<li>(context.image? '\nThe response image is provided.\n' : '')</li>
<li>'\nRespond to this message and pretend to be emotional (e.g.'</li>
<li>messageStorage.emotions.join(', ') + '):\n'</li>
<li>prompt</li>
<li>(context.memories? ('\nApply any relevant memories to your reponse:\n' + context.memories.join('\n')) : '')</li>
</ul>
<pre><code>
   * A string `q1` is generated by combining various parts of the prompt and context.
   * The response from the language model will be generated based on `q1`.

4. **Calling the Language Model**

   ```javascript
let result = await promptModel(q1)
</code></pre>
<ul>
<li>The language model is called with the generated string <code>q1</code> to produce a response.</li>
<li>The result is stored in the variable <code>result</code>.</li>
</ul>
<ol start="5">
<li><p><strong>Processing the Response</strong></p>
<pre><code class="language-javascript"></code></pre></li>
</ol>
<p>if(context.imagePath) {<br />
//...<br />
}</p>
<pre><code>
   * If an image path is present in the context, the response is processed accordingly.
   * If the response contains an image link, it is replaced with the correct link.
   * If the response does not contain an image link, it is added at the end.

6. **Storing the Final Response**

   ```javascript
if(session) {
  await storeResponse(false, session, result, void 0, otr)
}
</code></pre>
<ul>
<li>If a session is present, the final response is stored using the <code>storeResponse</code> function.</li>
</ul>
<ol start="7">
<li><p><strong>Returning the Final Response</strong></p>
<pre><code class="language-javascript"></code></pre></li>
</ol>
<p>return result</p>
<pre><code>
   * The final response is returned by the function.

### Export Statement

```javascript
module.exports = handleConversation
</code></pre>
<ul>
<li>The <code>handleConversation</code> function is exported as a module.</li>
</ul>

</body>

</html>