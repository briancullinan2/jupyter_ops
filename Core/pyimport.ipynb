{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "get python params?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inspect\n",
    "\n",
    "\n",
    "def get_parameter_names(source):\n",
    "    \"\"\"\n",
    "    Extracts parameter names from a function using the ast module.\n",
    "\n",
    "    Args:\n",
    "        func: The function to inspect.\n",
    "\n",
    "    Returns:\n",
    "        A list of parameter names as strings.\n",
    "    \"\"\"\n",
    "    #source = inspect.getsource(func)\n",
    "    tree = ast.parse(source)\n",
    "    function_def = next((node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)), None)\n",
    "\n",
    "    if function_def:\n",
    "        return [arg.arg for arg in function_def.args.args]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "__all__ = {\n",
    "  \"get_parameter_names\": get_parameter_names,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### import notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "\n",
    "def import_notebook(query_str, ctx):\n",
    "    from Core import search_whoosh\n",
    "    \"\"\"Searches the Whoosh index and returns a module of the retrieved code.\"\"\"\n",
    "    results = search_whoosh(query_str)\n",
    "    \n",
    "    if not results:\n",
    "        raise ImportError(f\"No matching notebook found for query: {query_str}\")\n",
    "    \n",
    "    module = types.ModuleType(results[0][\"filename\"])\n",
    "    module.__file__ = results[0][\"filename\"]\n",
    "    module.import_notebook = import_notebook\n",
    "\n",
    "    exec(results[0][\"code\"], module.__dict__)  # Execute the first matching cell in the module namespace\n",
    "    \n",
    "    for name in vars(module)['__all__']:\n",
    "        # setattr(vars(module)['__all__'], name, vars(module)['__all__'][name])\n",
    "        ctx[name] = vars(module)['__all__'][name]\n",
    "        module.__dict__[name] = vars(module)['__all__'][name]\n",
    "        globals()[name] = vars(module)['__all__'][name]\n",
    "\n",
    "    return vars(module)['__all__']\n",
    "\n",
    "__all__ = {\n",
    "  \"import_notebook\": import_notebook,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### accumulate markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "def get_questions(source, markdown):\n",
    "    \"\"\"Extracts questions from markdown and source code.\"\"\"\n",
    "    match_questions = re.compile(r'^.*\\?.*$', re.IGNORECASE | re.MULTILINE)\n",
    "    \n",
    "    questions = [re.sub(r'how to|\\?|#+', '', q, flags=re.IGNORECASE).strip()\n",
    "                 for q in match_questions.findall(markdown)]\n",
    "    \n",
    "    questions += [re.sub(r'how to|\\?|#+', '', q, flags=re.IGNORECASE).strip()\n",
    "                  for q in match_questions.findall(source) if 'how to' in q.lower()]\n",
    "    \n",
    "    questions.sort(key=len)\n",
    "    return questions + [questions[0]] if questions else ['']\n",
    "\n",
    "def accumulate_markdown(cells):\n",
    "    \"\"\"Accumulates markdown leading up to code cells.\"\"\"\n",
    "    codes = [c for c in cells if c[\"cell_type\"] == \"code\"]\n",
    "    result = []\n",
    "    \n",
    "    for i, code_cell in enumerate(codes):\n",
    "        from_idx = cells.index(codes[i-1]) + 1 if i > 0 else 0\n",
    "        to_idx = cells.index(code_cell)\n",
    "        markdown = \"\\n\".join(\"\".join(m[\"source\"]) for m in cells[from_idx:to_idx])\n",
    "        code = \"\".join(code_cell[\"source\"])\n",
    "        result.append({\n",
    "            \"id\": code_cell[\"id\"], \n",
    "            \"language\": code_cell[\"language\"], \n",
    "            \"from\": from_idx, \n",
    "            \"to\": to_idx, \n",
    "            \"markdown\": markdown, \n",
    "            \"code\": code\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "def cache_cells(filename):\n",
    "    from Core import get_cells\n",
    "    \"\"\"Parses a Jupyter notebook, extracts relevant cells, and generates cache entries.\"\"\"\n",
    "    filename = os.path.abspath(filename)\n",
    "    mtime = os.path.getmtime(filename)\n",
    "    \n",
    "    cells = get_cells(filename)\n",
    "    new_cache = accumulate_markdown(cells)\n",
    "    \n",
    "    return [{\n",
    "        \"id\": f\"{os.path.basename(filename)}[{i}]\",\n",
    "        \"filename\": filename,\n",
    "        \"mtime\": datetime.datetime.fromtimestamp(mtime),\n",
    "        \"questions\": get_questions(c[\"code\"], c[\"markdown\"]),\n",
    "        \"notebook\": os.path.basename(filename),\n",
    "        **c\n",
    "    } for i, c in enumerate(new_cache)]\n",
    "\n",
    "\n",
    "__all__ = {\n",
    "  \"cache_cells\": cache_cells,\n",
    "  \"accumulate_markdown\": accumulate_markdown,\n",
    "  \"get_questions\": get_questions,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### initialize database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID, DATETIME, KEYWORD\n",
    "from whoosh.qparser import QueryParser, MultifieldParser\n",
    "from whoosh.writing import AsyncWriter\n",
    "\n",
    "# Define schema for Whoosh index\n",
    "schema = Schema(mtime=DATETIME(stored=True), id=ID(stored=True), questions=TEXT(stored=True), filename=TEXT(stored=True), code=TEXT(stored=True))\n",
    "\n",
    "# Ensure index directory exists\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "    index = create_in(\"indexdir\", schema)\n",
    "else:\n",
    "    from whoosh.index import open_dir\n",
    "    index = open_dir(\"indexdir\")\n",
    "\n",
    "def store_in_whoosh(cells):\n",
    "    \"\"\"Stores extracted cells in Whoosh index.\"\"\"\n",
    "    writer = AsyncWriter(index)\n",
    "    for cell in cells:\n",
    "        if 'code' in cell: # and cell[\"language\"] == \"python\":\n",
    "            # print(cell[\"questions\"], cell[\"filename\"])\n",
    "            writer.add_document(mtime=cell[\"mtime\"], id=cell[\"id\"], questions=\" \".join(cell[\"questions\"]), filename=cell[\"filename\"], code=cell[\"code\"])\n",
    "            # writer.update_document(id=cell[\"id\"], questions=\" \".join(cell[\"questions\"]), filename=cell[\"filename\"], code=cell[\"code\"])\n",
    "    writer.commit()\n",
    "\n",
    "globals()['first'] = True\n",
    "def search_whoosh(question):\n",
    "#  with index.searcher() as searcher:\n",
    "#    query = QueryParser(\"questions\", index.schema).parse(question)  # Fuzzy search\n",
    "#    results = searcher.search(query)\n",
    "#    return results\n",
    "    if globals()['first']:\n",
    "        scan_directory(os.path.join(os.path.dirname(__file__), '..'), 3)\n",
    "        globals()['first'] = False\n",
    "\n",
    "    with index.searcher() as searcher:\n",
    "        parser = MultifieldParser([\"filename\", \"questions\"], schema=schema)\n",
    "        query = parser.parse(question)\n",
    "        #results = searcher.search(query, limit=10)  # Adjust limit as needed\n",
    "        results = searcher.search(query)  # Adjust limit as needed\n",
    "        return [{\"filename\": r[\"filename\"], \"code\": r[\"code\"]} for r in results]\n",
    "\n",
    "def scan_directory(directory, limit):\n",
    "    from Core import cache_cells\n",
    "    \"\"\"Recursively scans a directory for notebooks and stores extracted cells in Whoosh index.\"\"\"\n",
    "    all_cells = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.startswith(\".\"):\n",
    "                continue\n",
    "\n",
    "            if os.path.basename(root).startswith(\".\"):\n",
    "                continue\n",
    "\n",
    "            if file.endswith(\".ipynb\"):\n",
    "\n",
    "                # TODO: compare date time and delete notebooks only if outdated\n",
    "                #parser = QueryParser(\"date\", schema=ix.schema)\n",
    "                #query = DateRange(\"date\", datetime(1, 1, 1), datetime())\n",
    "                #results = searcher.search(query)\n",
    "\n",
    "                notebook_path = os.path.join(root, file)\n",
    "                parser = QueryParser(\"filename\", schema=schema)\n",
    "                query = parser.parse(os.path.abspath(notebook_path))\n",
    "                results = index.searcher().search(query)\n",
    "                if(not results or len(results) == 0\n",
    "                    or results[0]['mtime'] < datetime.datetime.fromtimestamp(os.path.getmtime(os.path.abspath(notebook_path)))):\n",
    "                    print(\"replacing: \", notebook_path)\n",
    "                    writer = AsyncWriter(index)\n",
    "                    writer.delete_by_query(query, index.searcher())\n",
    "                    writer.commit()\n",
    "                    all_cells.extend(cache_cells(notebook_path))\n",
    "            \n",
    "\n",
    "    store_in_whoosh(all_cells)\n",
    "    print(f\"Stored {len(all_cells)} cells in Whoosh index.\")\n",
    "\n",
    "\n",
    "__all__ = {\n",
    "  \"scan_directory\": scan_directory,\n",
    "  \"search_whoosh\": search_whoosh,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### get_cells(notebook_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def get_cells(notebook_path, types=['*', 'code']):\n",
    "    \"\"\"Extract cells from a Jupyter Notebook with additional metadata.\"\"\"\n",
    "    notebook_path = os.path.abspath(notebook_path)\n",
    "\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    kernel = notebook.get('metadata', {}).get('kernelspec', {})\n",
    "    \n",
    "    cells = [\n",
    "        {\n",
    "            **cell,\n",
    "            \"language\": (cell.get(\"metadata\", {}).get(\"vscode\", {}).get(\"languageId\") or\n",
    "                         kernel.get(\"language\") or\n",
    "                         notebook.get(\"metadata\", {}).get(\"language_info\", {}).get(\"name\", \"\")),\n",
    "            \"filename\": notebook_path,\n",
    "            \"id\": f\"{os.path.basename(notebook_path)}[{i}]\"\n",
    "        }\n",
    "        for i, cell in enumerate(notebook.get(\"cells\", []))\n",
    "        if '*' in types or cell.get(\"cell_type\") in types\n",
    "    ]\n",
    "\n",
    "    return cells\n",
    "\n",
    "__all__ = {\n",
    "  \"get_cells\": get_cells\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### run()\n",
    "\n",
    "run python cells?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "\n",
    "def run():\n",
    "    from Core import search_whoosh, import_notebook, get_parameter_names\n",
    "    if len(sys.argv) < 3:\n",
    "        print(\"Usage: python script.py <notebook_path> <function_args>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    notebook_path = sys.argv[1]\n",
    "    inputs = sys.argv[2:]\n",
    "\n",
    "    # Import the notebook as a module\n",
    "    results = search_whoosh(notebook_path)\n",
    "    #print(results[0]['code'])\n",
    "\n",
    "    module = import_notebook(notebook_path, globals())\n",
    "    print(module)\n",
    "\n",
    "    # Find the first function in the module\n",
    "    func = None\n",
    "    for name in list(module.keys()):\n",
    "        # TODO: support classes ? attr = getattr(module, name)\n",
    "        attr = module[name]\n",
    "        if callable(attr):\n",
    "            func = attr\n",
    "            break\n",
    "\n",
    "    if not func:\n",
    "        print(\"No function found in the notebook.\")\n",
    "        sys.exit(1)\n",
    "    print(func)\n",
    "\n",
    "    # Extract parameters and map inputs\n",
    "    params = get_parameter_names(results[0]['code'])\n",
    "    print(params)\n",
    "    mapped_inputs = []\n",
    "\n",
    "    for param in params:\n",
    "        for i, arg in enumerate(inputs):\n",
    "            if arg.startswith(f\"--{param}=\"):\n",
    "                mapped_inputs.append(arg.split(\"=\")[1])\n",
    "                break\n",
    "        else:\n",
    "            mapped_inputs.append(inputs.pop(0) if inputs else None)\n",
    "\n",
    "    # Convert types based on function annotations (if available)\n",
    "    if hasattr(func, '__annotations__'):\n",
    "        func_annotations = func.__annotations__\n",
    "        for i, param in enumerate(params):\n",
    "            if param in func_annotations:\n",
    "                mapped_inputs[i] = func_annotations[param](mapped_inputs[i])\n",
    "\n",
    "    # Execute the function\n",
    "    result = func(*mapped_inputs)\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__run__\":\n",
    "    run()\n",
    "\n",
    "__all__ = {\n",
    "  \"run\": run\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
